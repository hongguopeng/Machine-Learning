{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 信用卡欺詐檢測\n",
    "基於信用卡交易記錄數據建立分類模型來預測哪些交易記錄是異常的哪些是正常的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 請解壓縮data.rar，取得本程式之數據"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peng\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\peng\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\peng\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\peng\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\peng\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\peng\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\peng\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE , BorderlineSMOTE , ADASYN\n",
    "from sklearn.preprocessing import MinMaxScaler , StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "數據讀取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "5  0.260314 -0.568671  ... -0.208254 -0.559825 -0.026398 -0.371427 -0.232794   \n",
       "6  0.081213  0.464960  ... -0.167716 -0.270710 -0.154104 -0.780055  0.750137   \n",
       "7 -3.807864  0.615375  ...  1.943465 -1.015455  0.057504 -0.649709 -0.415267   \n",
       "8  0.851084 -0.392048  ... -0.073425 -0.268092 -0.204233  1.011592  0.373205   \n",
       "9  0.069539 -0.736727  ... -0.246914 -0.633753 -0.120794 -0.385050 -0.069733   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "5  0.105915  0.253844  0.081080    3.67      0  \n",
       "6 -0.257237  0.034507  0.005168    4.99      0  \n",
       "7 -0.051634 -1.206921 -1.085339   40.80      0  \n",
       "8 -0.384157  0.011747  0.142404   93.20      0  \n",
       "9  0.094199  0.246219  0.083076    3.68      0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('creditcard.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "數據標簽分布很不平衡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "負樣本比例 : 99.83%\n",
      "正樣本比例 : 0.17%\n"
     ]
    }
   ],
   "source": [
    "count_classes = data['Class'].value_counts()\n",
    "print('負樣本比例 : {:.2%}'.format(count_classes[0] / count_classes.sum()))\n",
    "print('正樣本比例 : {:.2%}'.format(count_classes[1] / count_classes.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Class'] # label\n",
    "X = data.drop(['Time' , 'Class'] , axis = 1) # feature\n",
    "\n",
    "# 整個數據集進行劃分\n",
    "x_train , x_test , y_train , y_test = train_test_split(X , y , test_size = 0.3 , random_state = 0)\n",
    "x_train = x_train.values\n",
    "x_test = x_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "對數據做normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "怎麼對data進行採樣與組合，在Siamese Network中非常重要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data , label , batch_size = 500 , class_num = 2):\n",
    "\n",
    "    # 收集500組data，每一組會有2筆data\n",
    "    # 其中250組為similar_data_set，每一組data中包含2筆相同class的data\n",
    "    # 另外250組data為dissimilar_data_set，每一組data中包含2筆不同class的data\n",
    "    data_set , label_set = data , label\n",
    "\n",
    "    similar_data_set = None\n",
    "    similar_label_set = None\n",
    "    for i in range(0 , class_num):\n",
    "        # 從第i個class中的data中挑出250筆data成為data_set[index]\n",
    "        # data_set[index] → [250 , 29]\n",
    "        index = np.random.choice(np.where(label_set == i)[0] ,\n",
    "                                 size = int(batch_size / class_num) ,\n",
    "                                 replace = False)\n",
    "\n",
    "        # 將data_set[index]中的data分為125組data，成為similar_data_pair\n",
    "        # 每一組data中包含2筆相同class的data\n",
    "        # similar_data_pair → [125 , 2 , 29]\n",
    "        similar_data_pair = np.reshape(data_set[index] , [int(batch_size / 2 / class_num) , 2 , -1])\n",
    "        if similar_data_set is None:\n",
    "            similar_data_set = similar_data_pair\n",
    "        else:\n",
    "            # similar_data_set → [250 , 2 , 29] (執行迴圈2次，沿著axis 0，將similar_data_pair堆疊2次)\n",
    "            similar_data_set = np.concatenate([similar_data_set , similar_data_pair] , axis = 0)\n",
    "\n",
    "        # 決定每一組data所對應的label\n",
    "        # similar_label_pair → [25 , 2 , 2]\n",
    "        # label為0的similar_label_pair[: , : , 0] = 1\n",
    "        # label1的similar_label_pair[: , : , 1] = 1\n",
    "        similar_label_pair = np.zeros([int(batch_size / 2 / class_num) , 2 , class_num])\n",
    "        similar_label_pair[: , : , i] = 1\n",
    "        if similar_label_set is None:\n",
    "            similar_label_set = similar_label_pair\n",
    "        else:\n",
    "            # similar_data_set → [250 , 2 , 2] (執行迴圈2次，沿著axis 0，將similar_data_pair堆疊2次)\n",
    "            similar_label_set = np.concatenate([similar_label_set , similar_label_pair] , axis = 0)\n",
    "\n",
    "\n",
    "    base_num = len(label)\n",
    "    dissimilar_data_set = None\n",
    "    dissimilar_label_set = None\n",
    "    # 從0~base_num中隨機挑出250個不重複的數字成為index_a_set\n",
    "    # index_a_set為dissimilar_data_set中每組data中第1筆data的index\n",
    "    index_a_set = np.random.choice(range(0 , base_num) ,\n",
    "                                   size = int(batch_size / 2) ,\n",
    "                                   replace = False)\n",
    "    for i in range(0 , int(batch_size / 2)):\n",
    "        # label_a為dissimilar_data_set中每組data中第1筆data的label\n",
    "        index_a = index_a_set[i]\n",
    "        label_a = label_set[index_a]\n",
    "        # label_b為dissimilar_data_set中每組data中第2筆data的label\n",
    "        # 執行迴圈直到label_a不等於label_b為止\n",
    "        while True:\n",
    "            index_b = np.random.randint(0 , base_num)\n",
    "            label_b = label_set[index_b]\n",
    "            if label_b != label_a:\n",
    "                break\n",
    "\n",
    "        # data_set[index_a] → [29 , ] ⟹ data_a → [1 , 29]\n",
    "        # data_set[index_b] → [29 , ] ⟹ data_b → [1 , 29]\n",
    "        data_a = np.reshape(data_set[index_a] , [1 , -1])\n",
    "        data_b = np.reshape(data_set[index_b] , [1 , -1])\n",
    "        # dissimilar_data_pair → [2 , 29]\n",
    "        dissimilar_data_pair = np.concatenate([data_a , data_b] , axis = 0)\n",
    "        # dissimilar_data_pair → [1 , 2 , 29]\n",
    "        dissimilar_data_pair = np.expand_dims(dissimilar_data_pair , axis = 0)\n",
    "    \n",
    "        if dissimilar_data_set is None:\n",
    "            dissimilar_data_set = dissimilar_data_pair\n",
    "        else:\n",
    "           # dissimilar_data_set → [250 , 2 , 29] (執行迴圈250次，沿著axis 0，將dissimilar_data_pair堆疊250次)\n",
    "           dissimilar_data_set = np.concatenate([dissimilar_data_set , dissimilar_data_pair] , axis = 0)\n",
    "\n",
    "        # class_label_a → [1 , 2]\n",
    "        # class_label_b → [1 , 2]\n",
    "        class_label_a = np.zeros([1 , class_num])\n",
    "        class_label_a[0 , label_a] = 1\n",
    "        class_label_b = np.zeros([1 , class_num])\n",
    "        class_label_b[0 , label_b] = 1\n",
    "        # dissimilar_label_pair → [2 , 2]\n",
    "        dissimilar_label_pair = np.concatenate([class_label_a , class_label_b] , axis = 0)\n",
    "        # dissimilar_label_pair → [1 , 2 , 2]\n",
    "        dissimilar_label_pair = np.expand_dims(dissimilar_label_pair , axis = 0)\n",
    "        if dissimilar_label_set is None:\n",
    "            dissimilar_label_set = dissimilar_label_pair\n",
    "        else:\n",
    "            # dissimilar_label_set → [250 , 2 , 2] (執行迴圈250次，沿著axis 0，將dissimilar_label_pair堆疊250次)\n",
    "            dissimilar_label_set = np.concatenate([dissimilar_label_set , dissimilar_label_pair] , axis = 0)\n",
    "\n",
    "    # data_set → [500 , 2 , 29]\n",
    "    data_set = np.concatenate([similar_data_set , dissimilar_data_set] , axis = 0)\n",
    "    # label_set → [500 , 2 , 2]\n",
    "    label_set = np.concatenate([similar_label_set , dissimilar_label_set] , axis = 0)\n",
    "    \n",
    "    # 對data進行shuffle\n",
    "    arr = np.arange(0 , batch_size)\n",
    "    np.random.shuffle(arr)\n",
    "    data_set = data_set[arr]\n",
    "    label_set  = label_set[arr]\n",
    "\n",
    "    return data_set , label_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter\n",
    "class_num = 2\n",
    "n_input = x_train.shape[-1]\n",
    "lr_siamese = 5e-4\n",
    "lr_classifier_1 = 5e-4\n",
    "lr_classifier_2 = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = tf.placeholder(tf.float32 , [None , 2 , n_input])\n",
    "x_a = input_tensor[: , 0 , :]\n",
    "x_b = input_tensor[: , 1 , :]\n",
    "y_true = tf.placeholder(tf.float32 , [None , 2 , class_num])\n",
    "y_true_a = y_true[: , 0 , :]\n",
    "y_true_b = y_true[: , 1 , :]\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layer(inputs , in_size , out_size , activaction_function = None , dropout = True):\n",
    "    # initializer = tf.glorot_uniform_initializer()\n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    Weights = tf.get_variable(initializer = initializer([in_size , out_size]) , name = 'w_a')\n",
    "    biases = tf.get_variable(initializer = tf.zeros([1 , out_size]) + 0.00001 , name = 'b_a')\n",
    "    Wx_plus_b = tf.add(tf.matmul(inputs , Weights) , biases)\n",
    "    if dropout:\n",
    "        Wx_plus_b = tf.nn.dropout(Wx_plus_b , keep_prob)\n",
    "\n",
    "    # here to activaction_function\n",
    "    if activaction_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activaction_function(Wx_plus_b , name = 'output')\n",
    "        \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(input_ , reuse = False):\n",
    "    with tf.variable_scope('layer_1'):\n",
    "        if reuse : tf.get_variable_scope().reuse_variables() \n",
    "        l1_f = add_layer(input_ , n_input , 50 , activaction_function = tf.nn.relu , dropout = True)\n",
    "\n",
    "    with tf.variable_scope('layer_2'):\n",
    "        if reuse : tf.get_variable_scope().reuse_variables() \n",
    "        l2_f = add_layer(l1_f , 50 , 30 , activaction_function = tf.nn.relu , dropout = True)\n",
    "\n",
    "    with tf.variable_scope('layer_3'):\n",
    "        if reuse : tf.get_variable_scope().reuse_variables()\n",
    "        l3_f = add_layer(l2_f , 30 , 20 , activaction_function = tf.nn.relu , dropout = True)\n",
    "\n",
    "    with tf.variable_scope('layer_4'):\n",
    "        if reuse : tf.get_variable_scope().reuse_variables() \n",
    "        l4_f = add_layer(l3_f , 20 , 10 , activaction_function = tf.nn.relu , dropout = True)\n",
    "\n",
    "    with tf.variable_scope('layer_5'):\n",
    "        if reuse : tf.get_variable_scope().reuse_variables() \n",
    "        l5_f = add_layer(l4_f , 10 , 5 , activaction_function = tf.nn.relu , dropout = False)\n",
    "\n",
    "    return l5_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "contrastive_loss的精華就在於希望同樣類別(相似)的data所產生的embedding vector越接近越好<br>\n",
    "而不同類別(不相似)的data所產生的embedding vector越接近margin越好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('siamese_network'):\n",
    "    with tf.variable_scope('feature_extractor'):\n",
    "        embedding_a = feature_extractor(x_a , reuse = False)\n",
    "        embedding_b = feature_extractor(x_b , reuse = True)\n",
    "    \n",
    "    with tf.variable_scope('euclidean_distance'):\n",
    "        distance = tf.reduce_sum(tf.pow(embedding_a - embedding_b , 2) , axis = 1)\n",
    "        distance = tf.sqrt(tf.maximum(distance , 1e-9))\n",
    "    \n",
    "    # 仿造一般多分類cross entropy的寫法\n",
    "    with tf.variable_scope('contrastive_loss'):\n",
    "        margin = 1\n",
    "        # decision_similarity其實就是y_true_a與y_true_b做內積的結果\n",
    "        # 只要y_true_a的1與y_true_b的1出現在同一個位置，也就是x_a與x_b屬於同一個class，decision_similarity就是1\n",
    "        # 只要y_true_a的1與y_true_b的1出現在不同的位置，也就是x_a與x_b屬於不同的class，decision_similarity就是0\n",
    "        # ❶ y_true_a → [1 , 0]  &  y_true_b → [1 , 0] ⟹ decision_similarity = 1  ,  1 - decision_similarity = 0\n",
    "        # ❶ y_true_a → [0 , 1]  &  y_true_b → [0 , 1] ⟹ decision_similarity = 1  ,  1 - decision_similarity = 0\n",
    "        # ❶ contrastive_loss = similarity = tf.square(distance)\n",
    "        # ❷ y_true_a → [1 , 0]  &  y_true_b → [0 , 1] ⟹ decision_similarity = 0  ,  1 - decision_similarity = 1\n",
    "        # ❷ y_true_a → [0 , 1]  &  y_true_b → [0 , 1] ⟹ decision_similarity = 0  ,  1 - decision_similarity = 1\n",
    "        # ❷ contrastive_loss = dissimilarity = tf.square(tf.maximum(margin - distance , 0))\n",
    "        decision_similarity = tf.reduce_sum(tf.multiply(y_true_a , y_true_b) , axis = 1)\n",
    "        similarity = tf.multiply(decision_similarity , tf.square(distance))\n",
    "        dissimilarity = tf.multiply(1 - decision_similarity , tf.square(tf.maximum(margin - distance , 0)))\n",
    "        contrastive_loss = tf.reduce_mean(similarity + dissimilarity)\n",
    "\n",
    "    with tf.variable_scope('accuracy'):\n",
    "        correct_siamese = tf.equal(tf.cast(tf.greater_equal(0.5 , distance) , tf.int32) , tf.cast(decision_similarity , tf.int32))\n",
    "        accuracy_siamese = tf.reduce_mean(tf.cast(correct_siamese , tf.float32))\n",
    "\n",
    "    with tf.variable_scope('optimizer'):\n",
    "        variable_siamese  = []\n",
    "        for i in tf.trainable_variables(): \n",
    "            if 'siamese_network' in i.name : variable_siamese.append(i)\n",
    "        train_siamese = tf.train.AdamOptimizer(lr_siamese).minimize(contrastive_loss , var_list = variable_siamese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以利用'feature_extractor'所得到的embedding vector，輸入至此linear classifier來的到分類結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('classifier_network'):\n",
    "    # 刻意只做了一個簡單的linear變換，為的就是要逼出'feature_extractor'的潛能，可以抽出良好的embedding vector\n",
    "    # 如果可以非常好的代表label為0或label為1的data，即為良好的embedding vector\n",
    "    with tf.variable_scope('layer_1'):\n",
    "        l1_c = add_layer(embedding_a , 5 , 2 , activaction_function = None , dropout = False)\n",
    "        \n",
    "    # the error between prediction and real data\n",
    "    with tf.variable_scope('cross_entropy'):\n",
    "        prediction_a_ = tf.nn.softmax(l1_c , axis = 1)\n",
    "        prediction_a_ = tf.clip_by_value(prediction_a_ , 1e-8 ,\n",
    "                                          tf.reduce_max(prediction_a_))\n",
    "        prediction_a = tf.log(prediction_a_)\n",
    "        cross_entropy_temp = -tf.reduce_sum(y_true_a * prediction_a , axis = 1)\n",
    "        cross_entropy = tf.reduce_mean(cross_entropy_temp)\n",
    "\n",
    "    with tf.variable_scope('accuracy'):\n",
    "        correct_classifier = tf.equal(tf.argmax(prediction_a , 1) , tf.argmax(y_true_a , 1))\n",
    "        correct_classifier = tf.cast(correct_classifier , tf.float32)\n",
    "        accuracy_classifier = tf.reduce_mean(correct_classifier)\n",
    "\n",
    "    with tf.variable_scope('optimizer'):\n",
    "        variable_classifier = []\n",
    "        for i in tf.trainable_variables():\n",
    "            if 'classifier_network' in i.name : variable_classifier.append(i)    \n",
    "        train_classifier_1 = tf.train.AdamOptimizer(lr_classifier_1).minimize(cross_entropy , var_list = variable_classifier)\n",
    "        train_classifier_2 = tf.train.AdamOptimizer(lr_classifier_2).minimize(cross_entropy , var_list = variable_siamese)\n",
    "        train_classifier = tf.group([train_classifier_1 , train_classifier_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "batch_i : 0\n",
      "training_loss_siamese : 0.3469\n",
      "training_accuracy_siamese : 53.40%\n",
      "training_loss_classifier : 0.6912\n",
      "training_accuracy_classifier : 55.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 0\n",
      "validation_loss_siamese : 0.5613\n",
      "validation_accuracy_siamese : 51.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 10\n",
      "training_loss_siamese : 0.3909\n",
      "training_accuracy_siamese : 50.20%\n",
      "training_loss_classifier : 0.6847\n",
      "training_accuracy_classifier : 58.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 10\n",
      "validation_loss_siamese : 0.4039\n",
      "validation_accuracy_siamese : 48.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 20\n",
      "training_loss_siamese : 0.3835\n",
      "training_accuracy_siamese : 52.40%\n",
      "training_loss_classifier : 0.6813\n",
      "training_accuracy_classifier : 61.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 20\n",
      "validation_loss_siamese : 0.4178\n",
      "validation_accuracy_siamese : 51.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 30\n",
      "training_loss_siamese : 0.4074\n",
      "training_accuracy_siamese : 50.60%\n",
      "training_loss_classifier : 0.6852\n",
      "training_accuracy_classifier : 62.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 30\n",
      "validation_loss_siamese : 0.4396\n",
      "validation_accuracy_siamese : 48.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 40\n",
      "training_loss_siamese : 0.4313\n",
      "training_accuracy_siamese : 50.00%\n",
      "training_loss_classifier : 0.6900\n",
      "training_accuracy_classifier : 66.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 40\n",
      "validation_loss_siamese : 0.4180\n",
      "validation_accuracy_siamese : 49.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 50\n",
      "training_loss_siamese : 0.4031\n",
      "training_accuracy_siamese : 49.80%\n",
      "training_loss_classifier : 0.6816\n",
      "training_accuracy_classifier : 66.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 50\n",
      "validation_loss_siamese : 0.4135\n",
      "validation_accuracy_siamese : 50.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 60\n",
      "training_loss_siamese : 0.3649\n",
      "training_accuracy_siamese : 50.20%\n",
      "training_loss_classifier : 0.6727\n",
      "training_accuracy_classifier : 70.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 60\n",
      "validation_loss_siamese : 0.4120\n",
      "validation_accuracy_siamese : 50.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 70\n",
      "training_loss_siamese : 0.3675\n",
      "training_accuracy_siamese : 50.20%\n",
      "training_loss_classifier : 0.6763\n",
      "training_accuracy_classifier : 63.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 70\n",
      "validation_loss_siamese : 0.4066\n",
      "validation_accuracy_siamese : 49.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 80\n",
      "training_loss_siamese : 0.3528\n",
      "training_accuracy_siamese : 50.80%\n",
      "training_loss_classifier : 0.6706\n",
      "training_accuracy_classifier : 69.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 80\n",
      "validation_loss_siamese : 0.3868\n",
      "validation_accuracy_siamese : 50.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 90\n",
      "training_loss_siamese : 0.3531\n",
      "training_accuracy_siamese : 49.20%\n",
      "training_loss_classifier : 0.6650\n",
      "training_accuracy_classifier : 72.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 90\n",
      "validation_loss_siamese : 0.3747\n",
      "validation_accuracy_siamese : 50.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 100\n",
      "training_loss_siamese : 0.3662\n",
      "training_accuracy_siamese : 49.60%\n",
      "training_loss_classifier : 0.6760\n",
      "training_accuracy_classifier : 64.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 100\n",
      "validation_loss_siamese : 0.3688\n",
      "validation_accuracy_siamese : 50.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 110\n",
      "training_loss_siamese : 0.3502\n",
      "training_accuracy_siamese : 50.40%\n",
      "training_loss_classifier : 0.6675\n",
      "training_accuracy_classifier : 72.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 110\n",
      "validation_loss_siamese : 0.3661\n",
      "validation_accuracy_siamese : 49.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 120\n",
      "training_loss_siamese : 0.3312\n",
      "training_accuracy_siamese : 50.00%\n",
      "training_loss_classifier : 0.6549\n",
      "training_accuracy_classifier : 79.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 120\n",
      "validation_loss_siamese : 0.3690\n",
      "validation_accuracy_siamese : 49.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 130\n",
      "training_loss_siamese : 0.3353\n",
      "training_accuracy_siamese : 50.20%\n",
      "training_loss_classifier : 0.6635\n",
      "training_accuracy_classifier : 71.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 130\n",
      "validation_loss_siamese : 0.3344\n",
      "validation_accuracy_siamese : 51.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 140\n",
      "training_loss_siamese : 0.3253\n",
      "training_accuracy_siamese : 50.20%\n",
      "training_loss_classifier : 0.6523\n",
      "training_accuracy_classifier : 73.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 140\n",
      "validation_loss_siamese : 0.3164\n",
      "validation_accuracy_siamese : 51.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 150\n",
      "training_loss_siamese : 0.2996\n",
      "training_accuracy_siamese : 50.60%\n",
      "training_loss_classifier : 0.6408\n",
      "training_accuracy_classifier : 81.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 150\n",
      "validation_loss_siamese : 0.3071\n",
      "validation_accuracy_siamese : 50.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 160\n",
      "training_loss_siamese : 0.2764\n",
      "training_accuracy_siamese : 51.20%\n",
      "training_loss_classifier : 0.6201\n",
      "training_accuracy_classifier : 90.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 160\n",
      "validation_loss_siamese : 0.2860\n",
      "validation_accuracy_siamese : 50.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 170\n",
      "training_loss_siamese : 0.2811\n",
      "training_accuracy_siamese : 52.40%\n",
      "training_loss_classifier : 0.6370\n",
      "training_accuracy_classifier : 75.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 170\n",
      "validation_loss_siamese : 0.2813\n",
      "validation_accuracy_siamese : 50.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 180\n",
      "training_loss_siamese : 0.2623\n",
      "training_accuracy_siamese : 52.40%\n",
      "training_loss_classifier : 0.6114\n",
      "training_accuracy_classifier : 89.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 180\n",
      "validation_loss_siamese : 0.2525\n",
      "validation_accuracy_siamese : 52.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 190\n",
      "training_loss_siamese : 0.2333\n",
      "training_accuracy_siamese : 57.20%\n",
      "training_loss_classifier : 0.5819\n",
      "training_accuracy_classifier : 90.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 190\n",
      "validation_loss_siamese : 0.2310\n",
      "validation_accuracy_siamese : 55.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 200\n",
      "training_loss_siamese : 0.1954\n",
      "training_accuracy_siamese : 64.00%\n",
      "training_loss_classifier : 0.5635\n",
      "training_accuracy_classifier : 90.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 200\n",
      "validation_loss_siamese : 0.2153\n",
      "validation_accuracy_siamese : 57.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 210\n",
      "training_loss_siamese : 0.2000\n",
      "training_accuracy_siamese : 66.60%\n",
      "training_loss_classifier : 0.5603\n",
      "training_accuracy_classifier : 88.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 210\n",
      "validation_loss_siamese : 0.2051\n",
      "validation_accuracy_siamese : 65.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 220\n",
      "training_loss_siamese : 0.1875\n",
      "training_accuracy_siamese : 71.00%\n",
      "training_loss_classifier : 0.5593\n",
      "training_accuracy_classifier : 89.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 220\n",
      "validation_loss_siamese : 0.1985\n",
      "validation_accuracy_siamese : 70.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 230\n",
      "training_loss_siamese : 0.1727\n",
      "training_accuracy_siamese : 76.00%\n",
      "training_loss_classifier : 0.5382\n",
      "training_accuracy_classifier : 92.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 230\n",
      "validation_loss_siamese : 0.1771\n",
      "validation_accuracy_siamese : 73.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 240\n",
      "training_loss_siamese : 0.2382\n",
      "training_accuracy_siamese : 67.60%\n",
      "training_loss_classifier : 0.5886\n",
      "training_accuracy_classifier : 74.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 240\n",
      "validation_loss_siamese : 0.1625\n",
      "validation_accuracy_siamese : 83.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 250\n",
      "training_loss_siamese : 0.2459\n",
      "training_accuracy_siamese : 65.80%\n",
      "training_loss_classifier : 0.5994\n",
      "training_accuracy_classifier : 72.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 250\n",
      "validation_loss_siamese : 0.1582\n",
      "validation_accuracy_siamese : 80.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 260\n",
      "training_loss_siamese : 0.1570\n",
      "training_accuracy_siamese : 79.40%\n",
      "training_loss_classifier : 0.5178\n",
      "training_accuracy_classifier : 90.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 260\n",
      "validation_loss_siamese : 0.1310\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 270\n",
      "training_loss_siamese : 0.1371\n",
      "training_accuracy_siamese : 86.40%\n",
      "training_loss_classifier : 0.5057\n",
      "training_accuracy_classifier : 93.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 270\n",
      "validation_loss_siamese : 0.1338\n",
      "validation_accuracy_siamese : 86.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 280\n",
      "training_loss_siamese : 0.1269\n",
      "training_accuracy_siamese : 86.80%\n",
      "training_loss_classifier : 0.4962\n",
      "training_accuracy_classifier : 93.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 280\n",
      "validation_loss_siamese : 0.1306\n",
      "validation_accuracy_siamese : 85.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 290\n",
      "training_loss_siamese : 0.1206\n",
      "training_accuracy_siamese : 87.60%\n",
      "training_loss_classifier : 0.4904\n",
      "training_accuracy_classifier : 93.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 290\n",
      "validation_loss_siamese : 0.1271\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 300\n",
      "training_loss_siamese : 0.0936\n",
      "training_accuracy_siamese : 93.40%\n",
      "training_loss_classifier : 0.4637\n",
      "training_accuracy_classifier : 96.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 300\n",
      "validation_loss_siamese : 0.1128\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 310\n",
      "training_loss_siamese : 0.1095\n",
      "training_accuracy_siamese : 89.00%\n",
      "training_loss_classifier : 0.4646\n",
      "training_accuracy_classifier : 92.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 310\n",
      "validation_loss_siamese : 0.0995\n",
      "validation_accuracy_siamese : 90.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 320\n",
      "training_loss_siamese : 0.0906\n",
      "training_accuracy_siamese : 93.00%\n",
      "training_loss_classifier : 0.4612\n",
      "training_accuracy_classifier : 94.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 320\n",
      "validation_loss_siamese : 0.1105\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 330\n",
      "training_loss_siamese : 0.1980\n",
      "training_accuracy_siamese : 73.40%\n",
      "training_loss_classifier : 0.5433\n",
      "training_accuracy_classifier : 80.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 330\n",
      "validation_loss_siamese : 0.1362\n",
      "validation_accuracy_siamese : 83.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 340\n",
      "training_loss_siamese : 0.1166\n",
      "training_accuracy_siamese : 87.20%\n",
      "training_loss_classifier : 0.4594\n",
      "training_accuracy_classifier : 94.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 340\n",
      "validation_loss_siamese : 0.1137\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 350\n",
      "training_loss_siamese : 0.0757\n",
      "training_accuracy_siamese : 95.40%\n",
      "training_loss_classifier : 0.4361\n",
      "training_accuracy_classifier : 98.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 350\n",
      "validation_loss_siamese : 0.1131\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 360\n",
      "training_loss_siamese : 0.1890\n",
      "training_accuracy_siamese : 74.20%\n",
      "training_loss_classifier : 0.5248\n",
      "training_accuracy_classifier : 80.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 360\n",
      "validation_loss_siamese : 0.1187\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 370\n",
      "training_loss_siamese : 0.0660\n",
      "training_accuracy_siamese : 95.60%\n",
      "training_loss_classifier : 0.4234\n",
      "training_accuracy_classifier : 97.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 370\n",
      "validation_loss_siamese : 0.1070\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 380\n",
      "training_loss_siamese : 0.0779\n",
      "training_accuracy_siamese : 92.40%\n",
      "training_loss_classifier : 0.4207\n",
      "training_accuracy_classifier : 97.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 380\n",
      "validation_loss_siamese : 0.1001\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 390\n",
      "training_loss_siamese : 0.0545\n",
      "training_accuracy_siamese : 96.60%\n",
      "training_loss_classifier : 0.4085\n",
      "training_accuracy_classifier : 98.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 390\n",
      "validation_loss_siamese : 0.1009\n",
      "validation_accuracy_siamese : 89.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 400\n",
      "training_loss_siamese : 0.0567\n",
      "training_accuracy_siamese : 95.40%\n",
      "training_loss_classifier : 0.4054\n",
      "training_accuracy_classifier : 96.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 400\n",
      "validation_loss_siamese : 0.0721\n",
      "validation_accuracy_siamese : 92.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 410\n",
      "training_loss_siamese : 0.1750\n",
      "training_accuracy_siamese : 76.20%\n",
      "training_loss_classifier : 0.5031\n",
      "training_accuracy_classifier : 82.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 410\n",
      "validation_loss_siamese : 0.0941\n",
      "validation_accuracy_siamese : 89.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 420\n",
      "training_loss_siamese : 0.0916\n",
      "training_accuracy_siamese : 89.60%\n",
      "training_loss_classifier : 0.4303\n",
      "training_accuracy_classifier : 93.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 420\n",
      "validation_loss_siamese : 0.0894\n",
      "validation_accuracy_siamese : 91.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 430\n",
      "training_loss_siamese : 0.1649\n",
      "training_accuracy_siamese : 77.20%\n",
      "training_loss_classifier : 0.4878\n",
      "training_accuracy_classifier : 84.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 430\n",
      "validation_loss_siamese : 0.0978\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 440\n",
      "training_loss_siamese : 0.0634\n",
      "training_accuracy_siamese : 95.20%\n",
      "training_loss_classifier : 0.3889\n",
      "training_accuracy_classifier : 98.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 440\n",
      "validation_loss_siamese : 0.1061\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 450\n",
      "training_loss_siamese : 0.0695\n",
      "training_accuracy_siamese : 94.40%\n",
      "training_loss_classifier : 0.3855\n",
      "training_accuracy_classifier : 97.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 450\n",
      "validation_loss_siamese : 0.1199\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 460\n",
      "training_loss_siamese : 0.0457\n",
      "training_accuracy_siamese : 96.60%\n",
      "training_loss_classifier : 0.3771\n",
      "training_accuracy_classifier : 98.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 460\n",
      "validation_loss_siamese : 0.1190\n",
      "validation_accuracy_siamese : 85.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 470\n",
      "training_loss_siamese : 0.0711\n",
      "training_accuracy_siamese : 92.40%\n",
      "training_loss_classifier : 0.3841\n",
      "training_accuracy_classifier : 96.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 470\n",
      "validation_loss_siamese : 0.0793\n",
      "validation_accuracy_siamese : 90.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 480\n",
      "training_loss_siamese : 0.0461\n",
      "training_accuracy_siamese : 95.40%\n",
      "training_loss_classifier : 0.3726\n",
      "training_accuracy_classifier : 98.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 480\n",
      "validation_loss_siamese : 0.0860\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 490\n",
      "training_loss_siamese : 0.1582\n",
      "training_accuracy_siamese : 77.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss_classifier : 0.4676\n",
      "training_accuracy_classifier : 85.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 490\n",
      "validation_loss_siamese : 0.1216\n",
      "validation_accuracy_siamese : 84.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 500\n",
      "training_loss_siamese : 0.1312\n",
      "training_accuracy_siamese : 81.40%\n",
      "training_loss_classifier : 0.4441\n",
      "training_accuracy_classifier : 87.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 500\n",
      "validation_loss_siamese : 0.0892\n",
      "validation_accuracy_siamese : 90.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 510\n",
      "training_loss_siamese : 0.0631\n",
      "training_accuracy_siamese : 94.20%\n",
      "training_loss_classifier : 0.3710\n",
      "training_accuracy_classifier : 98.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 510\n",
      "validation_loss_siamese : 0.1126\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 520\n",
      "training_loss_siamese : 0.0780\n",
      "training_accuracy_siamese : 91.40%\n",
      "training_loss_classifier : 0.3846\n",
      "training_accuracy_classifier : 95.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 520\n",
      "validation_loss_siamese : 0.0963\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 530\n",
      "training_loss_siamese : 0.0629\n",
      "training_accuracy_siamese : 93.40%\n",
      "training_loss_classifier : 0.3832\n",
      "training_accuracy_classifier : 96.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 530\n",
      "validation_loss_siamese : 0.0932\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 540\n",
      "training_loss_siamese : 0.0714\n",
      "training_accuracy_siamese : 91.80%\n",
      "training_loss_classifier : 0.3691\n",
      "training_accuracy_classifier : 95.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 540\n",
      "validation_loss_siamese : 0.0871\n",
      "validation_accuracy_siamese : 90.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 550\n",
      "training_loss_siamese : 0.0636\n",
      "training_accuracy_siamese : 93.00%\n",
      "training_loss_classifier : 0.3565\n",
      "training_accuracy_classifier : 96.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 550\n",
      "validation_loss_siamese : 0.0796\n",
      "validation_accuracy_siamese : 90.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 560\n",
      "training_loss_siamese : 0.0324\n",
      "training_accuracy_siamese : 97.60%\n",
      "training_loss_classifier : 0.3301\n",
      "training_accuracy_classifier : 99.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 560\n",
      "validation_loss_siamese : 0.0682\n",
      "validation_accuracy_siamese : 92.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 570\n",
      "training_loss_siamese : 0.0679\n",
      "training_accuracy_siamese : 91.40%\n",
      "training_loss_classifier : 0.3529\n",
      "training_accuracy_classifier : 96.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 570\n",
      "validation_loss_siamese : 0.0879\n",
      "validation_accuracy_siamese : 89.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 580\n",
      "training_loss_siamese : 0.0354\n",
      "training_accuracy_siamese : 97.20%\n",
      "training_loss_classifier : 0.3351\n",
      "training_accuracy_classifier : 98.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 580\n",
      "validation_loss_siamese : 0.0891\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 590\n",
      "training_loss_siamese : 0.0424\n",
      "training_accuracy_siamese : 96.00%\n",
      "training_loss_classifier : 0.3396\n",
      "training_accuracy_classifier : 97.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 590\n",
      "validation_loss_siamese : 0.0894\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 600\n",
      "training_loss_siamese : 0.0599\n",
      "training_accuracy_siamese : 94.00%\n",
      "training_loss_classifier : 0.3288\n",
      "training_accuracy_classifier : 98.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 600\n",
      "validation_loss_siamese : 0.1142\n",
      "validation_accuracy_siamese : 85.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 610\n",
      "training_loss_siamese : 0.1058\n",
      "training_accuracy_siamese : 85.20%\n",
      "training_loss_classifier : 0.3753\n",
      "training_accuracy_classifier : 93.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 610\n",
      "validation_loss_siamese : 0.1040\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 620\n",
      "training_loss_siamese : 0.0471\n",
      "training_accuracy_siamese : 95.60%\n",
      "training_loss_classifier : 0.3274\n",
      "training_accuracy_classifier : 98.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 620\n",
      "validation_loss_siamese : 0.0822\n",
      "validation_accuracy_siamese : 89.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 630\n",
      "training_loss_siamese : 0.0645\n",
      "training_accuracy_siamese : 93.20%\n",
      "training_loss_classifier : 0.3415\n",
      "training_accuracy_classifier : 95.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 630\n",
      "validation_loss_siamese : 0.0783\n",
      "validation_accuracy_siamese : 90.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 640\n",
      "training_loss_siamese : 0.0376\n",
      "training_accuracy_siamese : 96.40%\n",
      "training_loss_classifier : 0.3081\n",
      "training_accuracy_classifier : 98.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 640\n",
      "validation_loss_siamese : 0.0750\n",
      "validation_accuracy_siamese : 91.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 650\n",
      "training_loss_siamese : 0.1114\n",
      "training_accuracy_siamese : 84.40%\n",
      "training_loss_classifier : 0.4029\n",
      "training_accuracy_classifier : 88.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 650\n",
      "validation_loss_siamese : 0.0956\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 660\n",
      "training_loss_siamese : 0.1203\n",
      "training_accuracy_siamese : 83.80%\n",
      "training_loss_classifier : 0.3899\n",
      "training_accuracy_classifier : 90.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 660\n",
      "validation_loss_siamese : 0.0628\n",
      "validation_accuracy_siamese : 93.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 670\n",
      "training_loss_siamese : 0.1218\n",
      "training_accuracy_siamese : 84.80%\n",
      "training_loss_classifier : 0.4026\n",
      "training_accuracy_classifier : 89.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 670\n",
      "validation_loss_siamese : 0.1003\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 680\n",
      "training_loss_siamese : 0.0529\n",
      "training_accuracy_siamese : 93.60%\n",
      "training_loss_classifier : 0.3165\n",
      "training_accuracy_classifier : 97.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 680\n",
      "validation_loss_siamese : 0.1187\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 690\n",
      "training_loss_siamese : 0.0434\n",
      "training_accuracy_siamese : 95.60%\n",
      "training_loss_classifier : 0.3060\n",
      "training_accuracy_classifier : 98.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 690\n",
      "validation_loss_siamese : 0.0758\n",
      "validation_accuracy_siamese : 91.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 700\n",
      "training_loss_siamese : 0.0371\n",
      "training_accuracy_siamese : 95.80%\n",
      "training_loss_classifier : 0.2957\n",
      "training_accuracy_classifier : 98.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 700\n",
      "validation_loss_siamese : 0.1142\n",
      "validation_accuracy_siamese : 86.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 710\n",
      "training_loss_siamese : 0.1310\n",
      "training_accuracy_siamese : 83.40%\n",
      "training_loss_classifier : 0.4126\n",
      "training_accuracy_classifier : 87.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 710\n",
      "validation_loss_siamese : 0.0806\n",
      "validation_accuracy_siamese : 89.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 720\n",
      "training_loss_siamese : 0.0285\n",
      "training_accuracy_siamese : 97.00%\n",
      "training_loss_classifier : 0.2868\n",
      "training_accuracy_classifier : 99.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 720\n",
      "validation_loss_siamese : 0.1114\n",
      "validation_accuracy_siamese : 85.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 730\n",
      "training_loss_siamese : 0.0296\n",
      "training_accuracy_siamese : 96.80%\n",
      "training_loss_classifier : 0.2811\n",
      "training_accuracy_classifier : 98.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 730\n",
      "validation_loss_siamese : 0.0621\n",
      "validation_accuracy_siamese : 92.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 740\n",
      "training_loss_siamese : 0.0460\n",
      "training_accuracy_siamese : 94.40%\n",
      "training_loss_classifier : 0.3105\n",
      "training_accuracy_classifier : 96.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 740\n",
      "validation_loss_siamese : 0.1124\n",
      "validation_accuracy_siamese : 86.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 750\n",
      "training_loss_siamese : 0.1321\n",
      "training_accuracy_siamese : 82.20%\n",
      "training_loss_classifier : 0.4030\n",
      "training_accuracy_classifier : 87.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 750\n",
      "validation_loss_siamese : 0.1191\n",
      "validation_accuracy_siamese : 85.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 760\n",
      "training_loss_siamese : 0.0299\n",
      "training_accuracy_siamese : 96.80%\n",
      "training_loss_classifier : 0.2863\n",
      "training_accuracy_classifier : 98.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 760\n",
      "validation_loss_siamese : 0.0718\n",
      "validation_accuracy_siamese : 92.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 770\n",
      "training_loss_siamese : 0.0647\n",
      "training_accuracy_siamese : 92.20%\n",
      "training_loss_classifier : 0.3104\n",
      "training_accuracy_classifier : 95.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 770\n",
      "validation_loss_siamese : 0.0642\n",
      "validation_accuracy_siamese : 92.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 780\n",
      "training_loss_siamese : 0.0379\n",
      "training_accuracy_siamese : 95.00%\n",
      "training_loss_classifier : 0.2895\n",
      "training_accuracy_classifier : 98.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 780\n",
      "validation_loss_siamese : 0.0729\n",
      "validation_accuracy_siamese : 91.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 790\n",
      "training_loss_siamese : 0.0403\n",
      "training_accuracy_siamese : 95.40%\n",
      "training_loss_classifier : 0.2748\n",
      "training_accuracy_classifier : 98.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 790\n",
      "validation_loss_siamese : 0.0899\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 800\n",
      "training_loss_siamese : 0.0985\n",
      "training_accuracy_siamese : 87.00%\n",
      "training_loss_classifier : 0.3695\n",
      "training_accuracy_classifier : 90.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 800\n",
      "validation_loss_siamese : 0.0910\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 810\n",
      "training_loss_siamese : 0.0408\n",
      "training_accuracy_siamese : 95.20%\n",
      "training_loss_classifier : 0.2884\n",
      "training_accuracy_classifier : 96.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 810\n",
      "validation_loss_siamese : 0.1018\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 820\n",
      "training_loss_siamese : 0.0318\n",
      "training_accuracy_siamese : 96.20%\n",
      "training_loss_classifier : 0.2633\n",
      "training_accuracy_classifier : 98.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 820\n",
      "validation_loss_siamese : 0.0794\n",
      "validation_accuracy_siamese : 91.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 830\n",
      "training_loss_siamese : 0.1006\n",
      "training_accuracy_siamese : 88.20%\n",
      "training_loss_classifier : 0.3406\n",
      "training_accuracy_classifier : 92.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 830\n",
      "validation_loss_siamese : 0.0820\n",
      "validation_accuracy_siamese : 90.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 840\n",
      "training_loss_siamese : 0.0458\n",
      "training_accuracy_siamese : 94.20%\n",
      "training_loss_classifier : 0.2784\n",
      "training_accuracy_classifier : 97.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 840\n",
      "validation_loss_siamese : 0.1018\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 850\n",
      "training_loss_siamese : 0.0515\n",
      "training_accuracy_siamese : 93.60%\n",
      "training_loss_classifier : 0.2803\n",
      "training_accuracy_classifier : 97.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 850\n",
      "validation_loss_siamese : 0.1033\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 860\n",
      "training_loss_siamese : 0.0806\n",
      "training_accuracy_siamese : 88.60%\n",
      "training_loss_classifier : 0.3263\n",
      "training_accuracy_classifier : 92.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 860\n",
      "validation_loss_siamese : 0.0828\n",
      "validation_accuracy_siamese : 90.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 870\n",
      "training_loss_siamese : 0.0273\n",
      "training_accuracy_siamese : 96.80%\n",
      "training_loss_classifier : 0.2485\n",
      "training_accuracy_classifier : 99.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 870\n",
      "validation_loss_siamese : 0.1033\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 880\n",
      "training_loss_siamese : 0.0315\n",
      "training_accuracy_siamese : 96.40%\n",
      "training_loss_classifier : 0.2570\n",
      "training_accuracy_classifier : 98.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 880\n",
      "validation_loss_siamese : 0.1033\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 890\n",
      "training_loss_siamese : 0.0326\n",
      "training_accuracy_siamese : 96.20%\n",
      "training_loss_classifier : 0.2477\n",
      "training_accuracy_classifier : 98.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 890\n",
      "validation_loss_siamese : 0.0774\n",
      "validation_accuracy_siamese : 90.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 900\n",
      "training_loss_siamese : 0.0367\n",
      "training_accuracy_siamese : 95.80%\n",
      "training_loss_classifier : 0.2541\n",
      "training_accuracy_classifier : 98.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 900\n",
      "validation_loss_siamese : 0.0864\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 910\n",
      "training_loss_siamese : 0.0223\n",
      "training_accuracy_siamese : 97.60%\n",
      "training_loss_classifier : 0.2400\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 910\n",
      "validation_loss_siamese : 0.0683\n",
      "validation_accuracy_siamese : 91.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 920\n",
      "training_loss_siamese : 0.0255\n",
      "training_accuracy_siamese : 97.40%\n",
      "training_loss_classifier : 0.2406\n",
      "training_accuracy_classifier : 99.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 920\n",
      "validation_loss_siamese : 0.0794\n",
      "validation_accuracy_siamese : 90.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 930\n",
      "training_loss_siamese : 0.0530\n",
      "training_accuracy_siamese : 93.60%\n",
      "training_loss_classifier : 0.2716\n",
      "training_accuracy_classifier : 96.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 930\n",
      "validation_loss_siamese : 0.0827\n",
      "validation_accuracy_siamese : 91.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 940\n",
      "training_loss_siamese : 0.0146\n",
      "training_accuracy_siamese : 98.20%\n",
      "training_loss_classifier : 0.2329\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 940\n",
      "validation_loss_siamese : 0.0885\n",
      "validation_accuracy_siamese : 90.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 950\n",
      "training_loss_siamese : 0.0503\n",
      "training_accuracy_siamese : 93.60%\n",
      "training_loss_classifier : 0.2648\n",
      "training_accuracy_classifier : 96.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 950\n",
      "validation_loss_siamese : 0.0964\n",
      "validation_accuracy_siamese : 89.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 960\n",
      "training_loss_siamese : 0.1226\n",
      "training_accuracy_siamese : 84.00%\n",
      "training_loss_classifier : 0.3550\n",
      "training_accuracy_classifier : 90.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 960\n",
      "validation_loss_siamese : 0.0980\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 970\n",
      "training_loss_siamese : 0.0864\n",
      "training_accuracy_siamese : 89.20%\n",
      "training_loss_classifier : 0.3137\n",
      "training_accuracy_classifier : 92.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 970\n",
      "validation_loss_siamese : 0.0781\n",
      "validation_accuracy_siamese : 90.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 980\n",
      "training_loss_siamese : 0.0399\n",
      "training_accuracy_siamese : 95.60%\n",
      "training_loss_classifier : 0.2525\n",
      "training_accuracy_classifier : 97.00%\n",
      "\n",
      "******************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_i : 980\n",
      "validation_loss_siamese : 0.1075\n",
      "validation_accuracy_siamese : 85.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 990\n",
      "training_loss_siamese : 0.0335\n",
      "training_accuracy_siamese : 96.00%\n",
      "training_loss_classifier : 0.2466\n",
      "training_accuracy_classifier : 98.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 990\n",
      "validation_loss_siamese : 0.1167\n",
      "validation_accuracy_siamese : 84.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1000\n",
      "training_loss_siamese : 0.0884\n",
      "training_accuracy_siamese : 88.40%\n",
      "training_loss_classifier : 0.3163\n",
      "training_accuracy_classifier : 92.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 1000\n",
      "validation_loss_siamese : 0.0814\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1010\n",
      "training_loss_siamese : 0.0656\n",
      "training_accuracy_siamese : 91.40%\n",
      "training_loss_classifier : 0.2824\n",
      "training_accuracy_classifier : 95.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 1010\n",
      "validation_loss_siamese : 0.0712\n",
      "validation_accuracy_siamese : 90.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1020\n",
      "training_loss_siamese : 0.0670\n",
      "training_accuracy_siamese : 91.60%\n",
      "training_loss_classifier : 0.2808\n",
      "training_accuracy_classifier : 95.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 1020\n",
      "validation_loss_siamese : 0.0860\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1030\n",
      "training_loss_siamese : 0.0160\n",
      "training_accuracy_siamese : 98.60%\n",
      "training_loss_classifier : 0.2178\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 1030\n",
      "validation_loss_siamese : 0.0621\n",
      "validation_accuracy_siamese : 92.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1040\n",
      "training_loss_siamese : 0.0169\n",
      "training_accuracy_siamese : 98.00%\n",
      "training_loss_classifier : 0.2258\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 1040\n",
      "validation_loss_siamese : 0.0819\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1050\n",
      "training_loss_siamese : 0.0286\n",
      "training_accuracy_siamese : 97.00%\n",
      "training_loss_classifier : 0.2259\n",
      "training_accuracy_classifier : 98.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 1050\n",
      "validation_loss_siamese : 0.1011\n",
      "validation_accuracy_siamese : 86.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1060\n",
      "training_loss_siamese : 0.0645\n",
      "training_accuracy_siamese : 92.60%\n",
      "training_loss_classifier : 0.2611\n",
      "training_accuracy_classifier : 95.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 1060\n",
      "validation_loss_siamese : 0.0813\n",
      "validation_accuracy_siamese : 90.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1070\n",
      "training_loss_siamese : 0.0279\n",
      "training_accuracy_siamese : 97.00%\n",
      "training_loss_classifier : 0.2295\n",
      "training_accuracy_classifier : 97.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 1070\n",
      "validation_loss_siamese : 0.0913\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1080\n",
      "training_loss_siamese : 0.0274\n",
      "training_accuracy_siamese : 97.00%\n",
      "training_loss_classifier : 0.2283\n",
      "training_accuracy_classifier : 97.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 1080\n",
      "validation_loss_siamese : 0.0982\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1090\n",
      "training_loss_siamese : 0.0110\n",
      "training_accuracy_siamese : 98.80%\n",
      "training_loss_classifier : 0.1995\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 1090\n",
      "validation_loss_siamese : 0.0675\n",
      "validation_accuracy_siamese : 93.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1100\n",
      "training_loss_siamese : 0.0336\n",
      "training_accuracy_siamese : 95.20%\n",
      "training_loss_classifier : 0.2225\n",
      "training_accuracy_classifier : 98.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 1100\n",
      "validation_loss_siamese : 0.0709\n",
      "validation_accuracy_siamese : 91.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1110\n",
      "training_loss_siamese : 0.0304\n",
      "training_accuracy_siamese : 96.00%\n",
      "training_loss_classifier : 0.2146\n",
      "training_accuracy_classifier : 98.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 1110\n",
      "validation_loss_siamese : 0.0819\n",
      "validation_accuracy_siamese : 90.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1120\n",
      "training_loss_siamese : 0.0918\n",
      "training_accuracy_siamese : 86.80%\n",
      "training_loss_classifier : 0.2940\n",
      "training_accuracy_classifier : 93.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 1120\n",
      "validation_loss_siamese : 0.0712\n",
      "validation_accuracy_siamese : 91.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1130\n",
      "training_loss_siamese : 0.0281\n",
      "training_accuracy_siamese : 96.80%\n",
      "training_loss_classifier : 0.2143\n",
      "training_accuracy_classifier : 98.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 1130\n",
      "validation_loss_siamese : 0.0920\n",
      "validation_accuracy_siamese : 89.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1140\n",
      "training_loss_siamese : 0.0163\n",
      "training_accuracy_siamese : 98.20%\n",
      "training_loss_classifier : 0.2035\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 1140\n",
      "validation_loss_siamese : 0.1123\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1150\n",
      "training_loss_siamese : 0.0616\n",
      "training_accuracy_siamese : 91.40%\n",
      "training_loss_classifier : 0.2654\n",
      "training_accuracy_classifier : 94.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 1150\n",
      "validation_loss_siamese : 0.0907\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1160\n",
      "training_loss_siamese : 0.0149\n",
      "training_accuracy_siamese : 98.60%\n",
      "training_loss_classifier : 0.2024\n",
      "training_accuracy_classifier : 98.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 1160\n",
      "validation_loss_siamese : 0.0784\n",
      "validation_accuracy_siamese : 91.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1170\n",
      "training_loss_siamese : 0.0514\n",
      "training_accuracy_siamese : 93.40%\n",
      "training_loss_classifier : 0.2464\n",
      "training_accuracy_classifier : 96.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 1170\n",
      "validation_loss_siamese : 0.0775\n",
      "validation_accuracy_siamese : 91.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1180\n",
      "training_loss_siamese : 0.0181\n",
      "training_accuracy_siamese : 98.00%\n",
      "training_loss_classifier : 0.1954\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 1180\n",
      "validation_loss_siamese : 0.0917\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1190\n",
      "training_loss_siamese : 0.0154\n",
      "training_accuracy_siamese : 98.20%\n",
      "training_loss_classifier : 0.1949\n",
      "training_accuracy_classifier : 99.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 1190\n",
      "validation_loss_siamese : 0.1168\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1200\n",
      "training_loss_siamese : 0.0103\n",
      "training_accuracy_siamese : 98.80%\n",
      "training_loss_classifier : 0.1907\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 1200\n",
      "validation_loss_siamese : 0.0719\n",
      "validation_accuracy_siamese : 92.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1210\n",
      "training_loss_siamese : 0.0663\n",
      "training_accuracy_siamese : 91.00%\n",
      "training_loss_classifier : 0.2721\n",
      "training_accuracy_classifier : 93.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 1210\n",
      "validation_loss_siamese : 0.1142\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1220\n",
      "training_loss_siamese : 0.0113\n",
      "training_accuracy_siamese : 98.60%\n",
      "training_loss_classifier : 0.1829\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 1220\n",
      "validation_loss_siamese : 0.0938\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1230\n",
      "training_loss_siamese : 0.0315\n",
      "training_accuracy_siamese : 96.40%\n",
      "training_loss_classifier : 0.1949\n",
      "training_accuracy_classifier : 98.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 1230\n",
      "validation_loss_siamese : 0.1033\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1240\n",
      "training_loss_siamese : 0.0475\n",
      "training_accuracy_siamese : 94.40%\n",
      "training_loss_classifier : 0.2358\n",
      "training_accuracy_classifier : 97.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 1240\n",
      "validation_loss_siamese : 0.1149\n",
      "validation_accuracy_siamese : 86.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1250\n",
      "training_loss_siamese : 0.0246\n",
      "training_accuracy_siamese : 97.40%\n",
      "training_loss_classifier : 0.2029\n",
      "training_accuracy_classifier : 98.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 1250\n",
      "validation_loss_siamese : 0.0996\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1260\n",
      "training_loss_siamese : 0.0218\n",
      "training_accuracy_siamese : 98.00%\n",
      "training_loss_classifier : 0.1862\n",
      "training_accuracy_classifier : 98.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 1260\n",
      "validation_loss_siamese : 0.0856\n",
      "validation_accuracy_siamese : 90.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1270\n",
      "training_loss_siamese : 0.0366\n",
      "training_accuracy_siamese : 95.40%\n",
      "training_loss_classifier : 0.2117\n",
      "training_accuracy_classifier : 97.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 1270\n",
      "validation_loss_siamese : 0.0940\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1280\n",
      "training_loss_siamese : 0.0111\n",
      "training_accuracy_siamese : 98.60%\n",
      "training_loss_classifier : 0.1736\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 1280\n",
      "validation_loss_siamese : 0.0691\n",
      "validation_accuracy_siamese : 91.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1290\n",
      "training_loss_siamese : 0.0137\n",
      "training_accuracy_siamese : 98.40%\n",
      "training_loss_classifier : 0.1797\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 1290\n",
      "validation_loss_siamese : 0.0793\n",
      "validation_accuracy_siamese : 91.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1300\n",
      "training_loss_siamese : 0.0465\n",
      "training_accuracy_siamese : 94.20%\n",
      "training_loss_classifier : 0.2252\n",
      "training_accuracy_classifier : 97.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 1300\n",
      "validation_loss_siamese : 0.1152\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1310\n",
      "training_loss_siamese : 0.0108\n",
      "training_accuracy_siamese : 98.80%\n",
      "training_loss_classifier : 0.1742\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 1310\n",
      "validation_loss_siamese : 0.0937\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1320\n",
      "training_loss_siamese : 0.0254\n",
      "training_accuracy_siamese : 97.00%\n",
      "training_loss_classifier : 0.1836\n",
      "training_accuracy_classifier : 98.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 1320\n",
      "validation_loss_siamese : 0.0836\n",
      "validation_accuracy_siamese : 90.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1330\n",
      "training_loss_siamese : 0.0253\n",
      "training_accuracy_siamese : 96.60%\n",
      "training_loss_classifier : 0.1873\n",
      "training_accuracy_classifier : 98.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 1330\n",
      "validation_loss_siamese : 0.1012\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1340\n",
      "training_loss_siamese : 0.0201\n",
      "training_accuracy_siamese : 97.60%\n",
      "training_loss_classifier : 0.1825\n",
      "training_accuracy_classifier : 98.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 1340\n",
      "validation_loss_siamese : 0.1167\n",
      "validation_accuracy_siamese : 85.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1350\n",
      "training_loss_siamese : 0.0182\n",
      "training_accuracy_siamese : 97.60%\n",
      "training_loss_classifier : 0.1801\n",
      "training_accuracy_classifier : 98.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 1350\n",
      "validation_loss_siamese : 0.0814\n",
      "validation_accuracy_siamese : 91.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1360\n",
      "training_loss_siamese : 0.0148\n",
      "training_accuracy_siamese : 98.40%\n",
      "training_loss_classifier : 0.1671\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 1360\n",
      "validation_loss_siamese : 0.1200\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1370\n",
      "training_loss_siamese : 0.0111\n",
      "training_accuracy_siamese : 98.40%\n",
      "training_loss_classifier : 0.1638\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 1370\n",
      "validation_loss_siamese : 0.0918\n",
      "validation_accuracy_siamese : 90.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1380\n",
      "training_loss_siamese : 0.0590\n",
      "training_accuracy_siamese : 92.60%\n",
      "training_loss_classifier : 0.2317\n",
      "training_accuracy_classifier : 94.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 1380\n",
      "validation_loss_siamese : 0.1229\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1390\n",
      "training_loss_siamese : 0.0146\n",
      "training_accuracy_siamese : 98.20%\n",
      "training_loss_classifier : 0.1631\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 1390\n",
      "validation_loss_siamese : 0.1045\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1400\n",
      "training_loss_siamese : 0.0210\n",
      "training_accuracy_siamese : 97.00%\n",
      "training_loss_classifier : 0.1757\n",
      "training_accuracy_classifier : 98.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 1400\n",
      "validation_loss_siamese : 0.0837\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1410\n",
      "training_loss_siamese : 0.0346\n",
      "training_accuracy_siamese : 96.00%\n",
      "training_loss_classifier : 0.1931\n",
      "training_accuracy_classifier : 97.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 1410\n",
      "validation_loss_siamese : 0.1088\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1420\n",
      "training_loss_siamese : 0.0293\n",
      "training_accuracy_siamese : 96.40%\n",
      "training_loss_classifier : 0.1711\n",
      "training_accuracy_classifier : 99.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 1420\n",
      "validation_loss_siamese : 0.1041\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1430\n",
      "training_loss_siamese : 0.0165\n",
      "training_accuracy_siamese : 98.40%\n",
      "training_loss_classifier : 0.1679\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 1430\n",
      "validation_loss_siamese : 0.0910\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1440\n",
      "training_loss_siamese : 0.0504\n",
      "training_accuracy_siamese : 93.80%\n",
      "training_loss_classifier : 0.2145\n",
      "training_accuracy_classifier : 96.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 1440\n",
      "validation_loss_siamese : 0.0862\n",
      "validation_accuracy_siamese : 91.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1450\n",
      "training_loss_siamese : 0.0282\n",
      "training_accuracy_siamese : 97.00%\n",
      "training_loss_classifier : 0.1802\n",
      "training_accuracy_classifier : 98.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 1450\n",
      "validation_loss_siamese : 0.1174\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1460\n",
      "training_loss_siamese : 0.0285\n",
      "training_accuracy_siamese : 96.40%\n",
      "training_loss_classifier : 0.1722\n",
      "training_accuracy_classifier : 98.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 1460\n",
      "validation_loss_siamese : 0.0935\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1470\n",
      "training_loss_siamese : 0.0500\n",
      "training_accuracy_siamese : 94.20%\n",
      "training_loss_classifier : 0.2067\n",
      "training_accuracy_classifier : 96.60%\n",
      "\n",
      "******************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_i : 1470\n",
      "validation_loss_siamese : 0.0824\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1480\n",
      "training_loss_siamese : 0.0211\n",
      "training_accuracy_siamese : 97.00%\n",
      "training_loss_classifier : 0.1684\n",
      "training_accuracy_classifier : 98.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 1480\n",
      "validation_loss_siamese : 0.1058\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1490\n",
      "training_loss_siamese : 0.0296\n",
      "training_accuracy_siamese : 96.40%\n",
      "training_loss_classifier : 0.1762\n",
      "training_accuracy_classifier : 98.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 1490\n",
      "validation_loss_siamese : 0.0891\n",
      "validation_accuracy_siamese : 90.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1500\n",
      "training_loss_siamese : 0.0110\n",
      "training_accuracy_siamese : 99.00%\n",
      "training_loss_classifier : 0.1619\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 1500\n",
      "validation_loss_siamese : 0.1007\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1510\n",
      "training_loss_siamese : 0.0353\n",
      "training_accuracy_siamese : 96.20%\n",
      "training_loss_classifier : 0.1880\n",
      "training_accuracy_classifier : 97.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 1510\n",
      "validation_loss_siamese : 0.0622\n",
      "validation_accuracy_siamese : 93.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1520\n",
      "training_loss_siamese : 0.0234\n",
      "training_accuracy_siamese : 97.20%\n",
      "training_loss_classifier : 0.1651\n",
      "training_accuracy_classifier : 98.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 1520\n",
      "validation_loss_siamese : 0.0874\n",
      "validation_accuracy_siamese : 89.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1530\n",
      "training_loss_siamese : 0.0133\n",
      "training_accuracy_siamese : 98.60%\n",
      "training_loss_classifier : 0.1566\n",
      "training_accuracy_classifier : 99.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 1530\n",
      "validation_loss_siamese : 0.0734\n",
      "validation_accuracy_siamese : 91.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1540\n",
      "training_loss_siamese : 0.0288\n",
      "training_accuracy_siamese : 96.20%\n",
      "training_loss_classifier : 0.1610\n",
      "training_accuracy_classifier : 98.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 1540\n",
      "validation_loss_siamese : 0.0897\n",
      "validation_accuracy_siamese : 90.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1550\n",
      "training_loss_siamese : 0.0101\n",
      "training_accuracy_siamese : 98.40%\n",
      "training_loss_classifier : 0.1485\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 1550\n",
      "validation_loss_siamese : 0.0918\n",
      "validation_accuracy_siamese : 90.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1560\n",
      "training_loss_siamese : 0.0288\n",
      "training_accuracy_siamese : 96.40%\n",
      "training_loss_classifier : 0.1729\n",
      "training_accuracy_classifier : 98.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 1560\n",
      "validation_loss_siamese : 0.1013\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1570\n",
      "training_loss_siamese : 0.0223\n",
      "training_accuracy_siamese : 97.60%\n",
      "training_loss_classifier : 0.1609\n",
      "training_accuracy_classifier : 98.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 1570\n",
      "validation_loss_siamese : 0.1008\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1580\n",
      "training_loss_siamese : 0.0102\n",
      "training_accuracy_siamese : 98.80%\n",
      "training_loss_classifier : 0.1469\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 1580\n",
      "validation_loss_siamese : 0.0763\n",
      "validation_accuracy_siamese : 91.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1590\n",
      "training_loss_siamese : 0.0153\n",
      "training_accuracy_siamese : 98.40%\n",
      "training_loss_classifier : 0.1567\n",
      "training_accuracy_classifier : 98.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 1590\n",
      "validation_loss_siamese : 0.1067\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1600\n",
      "training_loss_siamese : 0.0345\n",
      "training_accuracy_siamese : 96.40%\n",
      "training_loss_classifier : 0.1692\n",
      "training_accuracy_classifier : 98.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 1600\n",
      "validation_loss_siamese : 0.0737\n",
      "validation_accuracy_siamese : 92.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1610\n",
      "training_loss_siamese : 0.0088\n",
      "training_accuracy_siamese : 99.00%\n",
      "training_loss_classifier : 0.1430\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 1610\n",
      "validation_loss_siamese : 0.1125\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1620\n",
      "training_loss_siamese : 0.0160\n",
      "training_accuracy_siamese : 98.20%\n",
      "training_loss_classifier : 0.1450\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 1620\n",
      "validation_loss_siamese : 0.0758\n",
      "validation_accuracy_siamese : 91.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1630\n",
      "training_loss_siamese : 0.0310\n",
      "training_accuracy_siamese : 96.00%\n",
      "training_loss_classifier : 0.1737\n",
      "training_accuracy_classifier : 97.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 1630\n",
      "validation_loss_siamese : 0.1215\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1640\n",
      "training_loss_siamese : 0.0099\n",
      "training_accuracy_siamese : 98.80%\n",
      "training_loss_classifier : 0.1389\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 1640\n",
      "validation_loss_siamese : 0.0762\n",
      "validation_accuracy_siamese : 92.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1650\n",
      "training_loss_siamese : 0.0189\n",
      "training_accuracy_siamese : 98.00%\n",
      "training_loss_classifier : 0.1403\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 1650\n",
      "validation_loss_siamese : 0.1074\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1660\n",
      "training_loss_siamese : 0.0138\n",
      "training_accuracy_siamese : 97.80%\n",
      "training_loss_classifier : 0.1362\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 1660\n",
      "validation_loss_siamese : 0.0914\n",
      "validation_accuracy_siamese : 90.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1670\n",
      "training_loss_siamese : 0.0177\n",
      "training_accuracy_siamese : 98.00%\n",
      "training_loss_classifier : 0.1438\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 1670\n",
      "validation_loss_siamese : 0.1220\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1680\n",
      "training_loss_siamese : 0.0132\n",
      "training_accuracy_siamese : 98.40%\n",
      "training_loss_classifier : 0.1417\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 1680\n",
      "validation_loss_siamese : 0.1070\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1690\n",
      "training_loss_siamese : 0.0141\n",
      "training_accuracy_siamese : 98.00%\n",
      "training_loss_classifier : 0.1423\n",
      "training_accuracy_classifier : 98.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 1690\n",
      "validation_loss_siamese : 0.0718\n",
      "validation_accuracy_siamese : 92.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1700\n",
      "training_loss_siamese : 0.0071\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.1287\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 1700\n",
      "validation_loss_siamese : 0.0899\n",
      "validation_accuracy_siamese : 90.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1710\n",
      "training_loss_siamese : 0.0104\n",
      "training_accuracy_siamese : 98.60%\n",
      "training_loss_classifier : 0.1407\n",
      "training_accuracy_classifier : 99.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 1710\n",
      "validation_loss_siamese : 0.1058\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1720\n",
      "training_loss_siamese : 0.0227\n",
      "training_accuracy_siamese : 97.00%\n",
      "training_loss_classifier : 0.1397\n",
      "training_accuracy_classifier : 99.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 1720\n",
      "validation_loss_siamese : 0.1059\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1730\n",
      "training_loss_siamese : 0.0133\n",
      "training_accuracy_siamese : 98.60%\n",
      "training_loss_classifier : 0.1354\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 1730\n",
      "validation_loss_siamese : 0.0951\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1740\n",
      "training_loss_siamese : 0.0115\n",
      "training_accuracy_siamese : 98.60%\n",
      "training_loss_classifier : 0.1299\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 1740\n",
      "validation_loss_siamese : 0.0858\n",
      "validation_accuracy_siamese : 89.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1750\n",
      "training_loss_siamese : 0.0107\n",
      "training_accuracy_siamese : 98.60%\n",
      "training_loss_classifier : 0.1340\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 1750\n",
      "validation_loss_siamese : 0.0832\n",
      "validation_accuracy_siamese : 91.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1760\n",
      "training_loss_siamese : 0.0135\n",
      "training_accuracy_siamese : 98.40%\n",
      "training_loss_classifier : 0.1346\n",
      "training_accuracy_classifier : 99.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 1760\n",
      "validation_loss_siamese : 0.0933\n",
      "validation_accuracy_siamese : 90.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1770\n",
      "training_loss_siamese : 0.0087\n",
      "training_accuracy_siamese : 99.00%\n",
      "training_loss_classifier : 0.1235\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 1770\n",
      "validation_loss_siamese : 0.0866\n",
      "validation_accuracy_siamese : 91.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1780\n",
      "training_loss_siamese : 0.0123\n",
      "training_accuracy_siamese : 98.60%\n",
      "training_loss_classifier : 0.1363\n",
      "training_accuracy_classifier : 98.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 1780\n",
      "validation_loss_siamese : 0.0969\n",
      "validation_accuracy_siamese : 90.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1790\n",
      "training_loss_siamese : 0.0119\n",
      "training_accuracy_siamese : 98.60%\n",
      "training_loss_classifier : 0.1272\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 1790\n",
      "validation_loss_siamese : 0.0778\n",
      "validation_accuracy_siamese : 91.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1800\n",
      "training_loss_siamese : 0.0129\n",
      "training_accuracy_siamese : 98.80%\n",
      "training_loss_classifier : 0.1283\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 1800\n",
      "validation_loss_siamese : 0.0905\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1810\n",
      "training_loss_siamese : 0.0099\n",
      "training_accuracy_siamese : 99.00%\n",
      "training_loss_classifier : 0.1193\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 1810\n",
      "validation_loss_siamese : 0.1162\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1820\n",
      "training_loss_siamese : 0.0077\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.1268\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 1820\n",
      "validation_loss_siamese : 0.1052\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1830\n",
      "training_loss_siamese : 0.0086\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.1284\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 1830\n",
      "validation_loss_siamese : 0.1134\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1840\n",
      "training_loss_siamese : 0.0235\n",
      "training_accuracy_siamese : 96.60%\n",
      "training_loss_classifier : 0.1508\n",
      "training_accuracy_classifier : 98.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 1840\n",
      "validation_loss_siamese : 0.1097\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1850\n",
      "training_loss_siamese : 0.0265\n",
      "training_accuracy_siamese : 96.40%\n",
      "training_loss_classifier : 0.1547\n",
      "training_accuracy_classifier : 97.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 1850\n",
      "validation_loss_siamese : 0.0957\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1860\n",
      "training_loss_siamese : 0.0118\n",
      "training_accuracy_siamese : 98.40%\n",
      "training_loss_classifier : 0.1191\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 1860\n",
      "validation_loss_siamese : 0.0939\n",
      "validation_accuracy_siamese : 90.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1870\n",
      "training_loss_siamese : 0.0159\n",
      "training_accuracy_siamese : 98.00%\n",
      "training_loss_classifier : 0.1224\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 1870\n",
      "validation_loss_siamese : 0.0764\n",
      "validation_accuracy_siamese : 91.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1880\n",
      "training_loss_siamese : 0.0108\n",
      "training_accuracy_siamese : 98.80%\n",
      "training_loss_classifier : 0.1189\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 1880\n",
      "validation_loss_siamese : 0.0834\n",
      "validation_accuracy_siamese : 90.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1890\n",
      "training_loss_siamese : 0.0049\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.1124\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 1890\n",
      "validation_loss_siamese : 0.0884\n",
      "validation_accuracy_siamese : 90.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1900\n",
      "training_loss_siamese : 0.0095\n",
      "training_accuracy_siamese : 98.60%\n",
      "training_loss_classifier : 0.1209\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 1900\n",
      "validation_loss_siamese : 0.0820\n",
      "validation_accuracy_siamese : 90.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1910\n",
      "training_loss_siamese : 0.0114\n",
      "training_accuracy_siamese : 98.80%\n",
      "training_loss_classifier : 0.1265\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 1910\n",
      "validation_loss_siamese : 0.1086\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1920\n",
      "training_loss_siamese : 0.0143\n",
      "training_accuracy_siamese : 98.60%\n",
      "training_loss_classifier : 0.1110\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 1920\n",
      "validation_loss_siamese : 0.0880\n",
      "validation_accuracy_siamese : 90.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1930\n",
      "training_loss_siamese : 0.0079\n",
      "training_accuracy_siamese : 99.00%\n",
      "training_loss_classifier : 0.1174\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 1930\n",
      "validation_loss_siamese : 0.0983\n",
      "validation_accuracy_siamese : 89.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1940\n",
      "training_loss_siamese : 0.0019\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.1076\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 1940\n",
      "validation_loss_siamese : 0.1330\n",
      "validation_accuracy_siamese : 85.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1950\n",
      "training_loss_siamese : 0.0237\n",
      "training_accuracy_siamese : 96.40%\n",
      "training_loss_classifier : 0.1325\n",
      "training_accuracy_classifier : 98.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 1950\n",
      "validation_loss_siamese : 0.0872\n",
      "validation_accuracy_siamese : 91.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1960\n",
      "training_loss_siamese : 0.0079\n",
      "training_accuracy_siamese : 99.00%\n",
      "training_loss_classifier : 0.1103\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_i : 1960\n",
      "validation_loss_siamese : 0.1304\n",
      "validation_accuracy_siamese : 85.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1970\n",
      "training_loss_siamese : 0.0128\n",
      "training_accuracy_siamese : 98.60%\n",
      "training_loss_classifier : 0.1178\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 1970\n",
      "validation_loss_siamese : 0.0719\n",
      "validation_accuracy_siamese : 90.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1980\n",
      "training_loss_siamese : 0.0051\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.1046\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 1980\n",
      "validation_loss_siamese : 0.0968\n",
      "validation_accuracy_siamese : 89.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 1990\n",
      "training_loss_siamese : 0.0041\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.1057\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 1990\n",
      "validation_loss_siamese : 0.0747\n",
      "validation_accuracy_siamese : 92.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2000\n",
      "training_loss_siamese : 0.0138\n",
      "training_accuracy_siamese : 98.60%\n",
      "training_loss_classifier : 0.1090\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 2000\n",
      "validation_loss_siamese : 0.1220\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2010\n",
      "training_loss_siamese : 0.0054\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.1096\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 2010\n",
      "validation_loss_siamese : 0.1109\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2020\n",
      "training_loss_siamese : 0.0189\n",
      "training_accuracy_siamese : 97.80%\n",
      "training_loss_classifier : 0.1357\n",
      "training_accuracy_classifier : 98.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 2020\n",
      "validation_loss_siamese : 0.1298\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2030\n",
      "training_loss_siamese : 0.0129\n",
      "training_accuracy_siamese : 98.60%\n",
      "training_loss_classifier : 0.1188\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 2030\n",
      "validation_loss_siamese : 0.0882\n",
      "validation_accuracy_siamese : 90.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2040\n",
      "training_loss_siamese : 0.0151\n",
      "training_accuracy_siamese : 98.20%\n",
      "training_loss_classifier : 0.1145\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 2040\n",
      "validation_loss_siamese : 0.0968\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2050\n",
      "training_loss_siamese : 0.0065\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.1055\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 2050\n",
      "validation_loss_siamese : 0.1011\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2060\n",
      "training_loss_siamese : 0.0173\n",
      "training_accuracy_siamese : 98.20%\n",
      "training_loss_classifier : 0.1225\n",
      "training_accuracy_classifier : 98.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 2060\n",
      "validation_loss_siamese : 0.1232\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2070\n",
      "training_loss_siamese : 0.0116\n",
      "training_accuracy_siamese : 98.60%\n",
      "training_loss_classifier : 0.1025\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 2070\n",
      "validation_loss_siamese : 0.1099\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2080\n",
      "training_loss_siamese : 0.0225\n",
      "training_accuracy_siamese : 97.60%\n",
      "training_loss_classifier : 0.1228\n",
      "training_accuracy_classifier : 98.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 2080\n",
      "validation_loss_siamese : 0.1074\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2090\n",
      "training_loss_siamese : 0.0175\n",
      "training_accuracy_siamese : 97.80%\n",
      "training_loss_classifier : 0.1144\n",
      "training_accuracy_classifier : 98.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 2090\n",
      "validation_loss_siamese : 0.1116\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2100\n",
      "training_loss_siamese : 0.0183\n",
      "training_accuracy_siamese : 97.80%\n",
      "training_loss_classifier : 0.1051\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 2100\n",
      "validation_loss_siamese : 0.1333\n",
      "validation_accuracy_siamese : 86.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2110\n",
      "training_loss_siamese : 0.0083\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.1088\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 2110\n",
      "validation_loss_siamese : 0.0905\n",
      "validation_accuracy_siamese : 90.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2120\n",
      "training_loss_siamese : 0.0035\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0943\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 2120\n",
      "validation_loss_siamese : 0.1029\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2130\n",
      "training_loss_siamese : 0.0150\n",
      "training_accuracy_siamese : 98.20%\n",
      "training_loss_classifier : 0.1112\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 2130\n",
      "validation_loss_siamese : 0.0628\n",
      "validation_accuracy_siamese : 93.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2140\n",
      "training_loss_siamese : 0.0106\n",
      "training_accuracy_siamese : 98.80%\n",
      "training_loss_classifier : 0.0993\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 2140\n",
      "validation_loss_siamese : 0.1164\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2150\n",
      "training_loss_siamese : 0.0058\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.0931\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 2150\n",
      "validation_loss_siamese : 0.1076\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2160\n",
      "training_loss_siamese : 0.0056\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0919\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 2160\n",
      "validation_loss_siamese : 0.1482\n",
      "validation_accuracy_siamese : 84.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2170\n",
      "training_loss_siamese : 0.0073\n",
      "training_accuracy_siamese : 99.00%\n",
      "training_loss_classifier : 0.1017\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 2170\n",
      "validation_loss_siamese : 0.1394\n",
      "validation_accuracy_siamese : 85.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2180\n",
      "training_loss_siamese : 0.0106\n",
      "training_accuracy_siamese : 98.60%\n",
      "training_loss_classifier : 0.1044\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 2180\n",
      "validation_loss_siamese : 0.1161\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2190\n",
      "training_loss_siamese : 0.0118\n",
      "training_accuracy_siamese : 98.40%\n",
      "training_loss_classifier : 0.1024\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 2190\n",
      "validation_loss_siamese : 0.1037\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2200\n",
      "training_loss_siamese : 0.0092\n",
      "training_accuracy_siamese : 98.60%\n",
      "training_loss_classifier : 0.1058\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 2200\n",
      "validation_loss_siamese : 0.1044\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2210\n",
      "training_loss_siamese : 0.0108\n",
      "training_accuracy_siamese : 98.40%\n",
      "training_loss_classifier : 0.1015\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 2210\n",
      "validation_loss_siamese : 0.1016\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2220\n",
      "training_loss_siamese : 0.0070\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.0942\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 2220\n",
      "validation_loss_siamese : 0.1262\n",
      "validation_accuracy_siamese : 86.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2230\n",
      "training_loss_siamese : 0.0098\n",
      "training_accuracy_siamese : 98.40%\n",
      "training_loss_classifier : 0.1046\n",
      "training_accuracy_classifier : 99.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 2230\n",
      "validation_loss_siamese : 0.1250\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2240\n",
      "training_loss_siamese : 0.0043\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0963\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 2240\n",
      "validation_loss_siamese : 0.1019\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2250\n",
      "training_loss_siamese : 0.0082\n",
      "training_accuracy_siamese : 98.60%\n",
      "training_loss_classifier : 0.0921\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 2250\n",
      "validation_loss_siamese : 0.1090\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2260\n",
      "training_loss_siamese : 0.0092\n",
      "training_accuracy_siamese : 98.60%\n",
      "training_loss_classifier : 0.0900\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 2260\n",
      "validation_loss_siamese : 0.1002\n",
      "validation_accuracy_siamese : 90.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2270\n",
      "training_loss_siamese : 0.0060\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.0904\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 2270\n",
      "validation_loss_siamese : 0.1031\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2280\n",
      "training_loss_siamese : 0.0111\n",
      "training_accuracy_siamese : 98.60%\n",
      "training_loss_classifier : 0.1025\n",
      "training_accuracy_classifier : 98.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 2280\n",
      "validation_loss_siamese : 0.0847\n",
      "validation_accuracy_siamese : 90.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2290\n",
      "training_loss_siamese : 0.0166\n",
      "training_accuracy_siamese : 98.00%\n",
      "training_loss_classifier : 0.1043\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 2290\n",
      "validation_loss_siamese : 0.1176\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2300\n",
      "training_loss_siamese : 0.0049\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0870\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 2300\n",
      "validation_loss_siamese : 0.1140\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2310\n",
      "training_loss_siamese : 0.0059\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0934\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 2310\n",
      "validation_loss_siamese : 0.1080\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2320\n",
      "training_loss_siamese : 0.0002\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0846\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 2320\n",
      "validation_loss_siamese : 0.0996\n",
      "validation_accuracy_siamese : 89.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2330\n",
      "training_loss_siamese : 0.0016\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0853\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 2330\n",
      "validation_loss_siamese : 0.1300\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2340\n",
      "training_loss_siamese : 0.0061\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0959\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 2340\n",
      "validation_loss_siamese : 0.1112\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2350\n",
      "training_loss_siamese : 0.0086\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.0941\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 2350\n",
      "validation_loss_siamese : 0.1404\n",
      "validation_accuracy_siamese : 85.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2360\n",
      "training_loss_siamese : 0.0067\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.0918\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 2360\n",
      "validation_loss_siamese : 0.1516\n",
      "validation_accuracy_siamese : 84.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2370\n",
      "training_loss_siamese : 0.0060\n",
      "training_accuracy_siamese : 98.60%\n",
      "training_loss_classifier : 0.0912\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 2370\n",
      "validation_loss_siamese : 0.1166\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2380\n",
      "training_loss_siamese : 0.0081\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.0819\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 2380\n",
      "validation_loss_siamese : 0.1523\n",
      "validation_accuracy_siamese : 83.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2390\n",
      "training_loss_siamese : 0.0131\n",
      "training_accuracy_siamese : 98.40%\n",
      "training_loss_classifier : 0.0976\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 2390\n",
      "validation_loss_siamese : 0.1288\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2400\n",
      "training_loss_siamese : 0.0212\n",
      "training_accuracy_siamese : 98.00%\n",
      "training_loss_classifier : 0.1067\n",
      "training_accuracy_classifier : 98.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 2400\n",
      "validation_loss_siamese : 0.0943\n",
      "validation_accuracy_siamese : 89.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2410\n",
      "training_loss_siamese : 0.0111\n",
      "training_accuracy_siamese : 98.80%\n",
      "training_loss_classifier : 0.0987\n",
      "training_accuracy_classifier : 99.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 2410\n",
      "validation_loss_siamese : 0.1046\n",
      "validation_accuracy_siamese : 89.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2420\n",
      "training_loss_siamese : 0.0081\n",
      "training_accuracy_siamese : 99.00%\n",
      "training_loss_classifier : 0.0864\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 2420\n",
      "validation_loss_siamese : 0.1265\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2430\n",
      "training_loss_siamese : 0.0101\n",
      "training_accuracy_siamese : 98.80%\n",
      "training_loss_classifier : 0.0952\n",
      "training_accuracy_classifier : 99.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 2430\n",
      "validation_loss_siamese : 0.0927\n",
      "validation_accuracy_siamese : 90.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2440\n",
      "training_loss_siamese : 0.0147\n",
      "training_accuracy_siamese : 98.60%\n",
      "training_loss_classifier : 0.0939\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 2440\n",
      "validation_loss_siamese : 0.0962\n",
      "validation_accuracy_siamese : 90.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2450\n",
      "training_loss_siamese : 0.0058\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0844\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_i : 2450\n",
      "validation_loss_siamese : 0.0989\n",
      "validation_accuracy_siamese : 90.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2460\n",
      "training_loss_siamese : 0.0026\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0805\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 2460\n",
      "validation_loss_siamese : 0.1034\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2470\n",
      "training_loss_siamese : 0.0066\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0785\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 2470\n",
      "validation_loss_siamese : 0.1044\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2480\n",
      "training_loss_siamese : 0.0019\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0812\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 2480\n",
      "validation_loss_siamese : 0.1065\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2490\n",
      "training_loss_siamese : 0.0043\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0748\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 2490\n",
      "validation_loss_siamese : 0.1521\n",
      "validation_accuracy_siamese : 84.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2500\n",
      "training_loss_siamese : 0.0075\n",
      "training_accuracy_siamese : 99.00%\n",
      "training_loss_classifier : 0.0901\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 2500\n",
      "validation_loss_siamese : 0.0750\n",
      "validation_accuracy_siamese : 92.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2510\n",
      "training_loss_siamese : 0.0066\n",
      "training_accuracy_siamese : 99.00%\n",
      "training_loss_classifier : 0.0886\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 2510\n",
      "validation_loss_siamese : 0.0990\n",
      "validation_accuracy_siamese : 89.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2520\n",
      "training_loss_siamese : 0.0054\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0789\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 2520\n",
      "validation_loss_siamese : 0.1113\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2530\n",
      "training_loss_siamese : 0.0063\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0787\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 2530\n",
      "validation_loss_siamese : 0.1578\n",
      "validation_accuracy_siamese : 84.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2540\n",
      "training_loss_siamese : 0.0024\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0786\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 2540\n",
      "validation_loss_siamese : 0.1130\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2550\n",
      "training_loss_siamese : 0.0026\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0781\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 2550\n",
      "validation_loss_siamese : 0.1085\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2560\n",
      "training_loss_siamese : 0.0062\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.0820\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 2560\n",
      "validation_loss_siamese : 0.1812\n",
      "validation_accuracy_siamese : 80.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2570\n",
      "training_loss_siamese : 0.0016\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0767\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 2570\n",
      "validation_loss_siamese : 0.1366\n",
      "validation_accuracy_siamese : 86.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2580\n",
      "training_loss_siamese : 0.0054\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0806\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 2580\n",
      "validation_loss_siamese : 0.1344\n",
      "validation_accuracy_siamese : 85.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2590\n",
      "training_loss_siamese : 0.0060\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.0817\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 2590\n",
      "validation_loss_siamese : 0.1595\n",
      "validation_accuracy_siamese : 83.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2600\n",
      "training_loss_siamese : 0.0007\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0726\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 2600\n",
      "validation_loss_siamese : 0.0978\n",
      "validation_accuracy_siamese : 90.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2610\n",
      "training_loss_siamese : 0.0065\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0863\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 2610\n",
      "validation_loss_siamese : 0.1173\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2620\n",
      "training_loss_siamese : 0.0048\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0731\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 2620\n",
      "validation_loss_siamese : 0.1217\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2630\n",
      "training_loss_siamese : 0.0032\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0759\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 2630\n",
      "validation_loss_siamese : 0.1097\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2640\n",
      "training_loss_siamese : 0.0016\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0711\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 2640\n",
      "validation_loss_siamese : 0.1211\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2650\n",
      "training_loss_siamese : 0.0031\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0697\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 2650\n",
      "validation_loss_siamese : 0.1309\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2660\n",
      "training_loss_siamese : 0.0065\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0797\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 2660\n",
      "validation_loss_siamese : 0.1069\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2670\n",
      "training_loss_siamese : 0.0032\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0745\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 2670\n",
      "validation_loss_siamese : 0.1294\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2680\n",
      "training_loss_siamese : 0.0159\n",
      "training_accuracy_siamese : 98.20%\n",
      "training_loss_classifier : 0.0872\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 2680\n",
      "validation_loss_siamese : 0.1108\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2690\n",
      "training_loss_siamese : 0.0066\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.0780\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 2690\n",
      "validation_loss_siamese : 0.1194\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2700\n",
      "training_loss_siamese : 0.0044\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0739\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 2700\n",
      "validation_loss_siamese : 0.1000\n",
      "validation_accuracy_siamese : 90.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2710\n",
      "training_loss_siamese : 0.0049\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0674\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 2710\n",
      "validation_loss_siamese : 0.1247\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2720\n",
      "training_loss_siamese : 0.0030\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0746\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 2720\n",
      "validation_loss_siamese : 0.1007\n",
      "validation_accuracy_siamese : 89.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2730\n",
      "training_loss_siamese : 0.0059\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.0707\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 2730\n",
      "validation_loss_siamese : 0.1344\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2740\n",
      "training_loss_siamese : 0.0057\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0776\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 2740\n",
      "validation_loss_siamese : 0.1183\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2750\n",
      "training_loss_siamese : 0.0055\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.0741\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 2750\n",
      "validation_loss_siamese : 0.1438\n",
      "validation_accuracy_siamese : 85.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2760\n",
      "training_loss_siamese : 0.0053\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0715\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 2760\n",
      "validation_loss_siamese : 0.1535\n",
      "validation_accuracy_siamese : 84.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2770\n",
      "training_loss_siamese : 0.0034\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0678\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 2770\n",
      "validation_loss_siamese : 0.0997\n",
      "validation_accuracy_siamese : 89.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2780\n",
      "training_loss_siamese : 0.0088\n",
      "training_accuracy_siamese : 98.60%\n",
      "training_loss_classifier : 0.0682\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 2780\n",
      "validation_loss_siamese : 0.1288\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2790\n",
      "training_loss_siamese : 0.0058\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0650\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 2790\n",
      "validation_loss_siamese : 0.1759\n",
      "validation_accuracy_siamese : 82.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2800\n",
      "training_loss_siamese : 0.0081\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.0736\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 2800\n",
      "validation_loss_siamese : 0.1261\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2810\n",
      "training_loss_siamese : 0.0073\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.0760\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 2810\n",
      "validation_loss_siamese : 0.1071\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2820\n",
      "training_loss_siamese : 0.0088\n",
      "training_accuracy_siamese : 99.00%\n",
      "training_loss_classifier : 0.0719\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 2820\n",
      "validation_loss_siamese : 0.1051\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2830\n",
      "training_loss_siamese : 0.0050\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0702\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 2830\n",
      "validation_loss_siamese : 0.1160\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2840\n",
      "training_loss_siamese : 0.0080\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.0755\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 2840\n",
      "validation_loss_siamese : 0.0999\n",
      "validation_accuracy_siamese : 89.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2850\n",
      "training_loss_siamese : 0.0064\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.0687\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 2850\n",
      "validation_loss_siamese : 0.1101\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2860\n",
      "training_loss_siamese : 0.0013\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0634\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 2860\n",
      "validation_loss_siamese : 0.0952\n",
      "validation_accuracy_siamese : 90.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2870\n",
      "training_loss_siamese : 0.0114\n",
      "training_accuracy_siamese : 98.60%\n",
      "training_loss_classifier : 0.0746\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 2870\n",
      "validation_loss_siamese : 0.1517\n",
      "validation_accuracy_siamese : 84.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2880\n",
      "training_loss_siamese : 0.0064\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.0704\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 2880\n",
      "validation_loss_siamese : 0.1123\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2890\n",
      "training_loss_siamese : 0.0032\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0618\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 2890\n",
      "validation_loss_siamese : 0.1103\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2900\n",
      "training_loss_siamese : 0.0025\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0622\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 2900\n",
      "validation_loss_siamese : 0.1009\n",
      "validation_accuracy_siamese : 90.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2910\n",
      "training_loss_siamese : 0.0054\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0686\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 2910\n",
      "validation_loss_siamese : 0.1030\n",
      "validation_accuracy_siamese : 90.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2920\n",
      "training_loss_siamese : 0.0044\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0622\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 2920\n",
      "validation_loss_siamese : 0.1144\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2930\n",
      "training_loss_siamese : 0.0074\n",
      "training_accuracy_siamese : 99.00%\n",
      "training_loss_classifier : 0.0723\n",
      "training_accuracy_classifier : 99.20%\n",
      "\n",
      "******************************\n",
      "batch_i : 2930\n",
      "validation_loss_siamese : 0.0873\n",
      "validation_accuracy_siamese : 91.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2940\n",
      "training_loss_siamese : 0.0000\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0597\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "batch_i : 2940\n",
      "validation_loss_siamese : 0.1181\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2950\n",
      "training_loss_siamese : 0.0025\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0649\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 2950\n",
      "validation_loss_siamese : 0.1086\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2960\n",
      "training_loss_siamese : 0.0031\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0653\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 2960\n",
      "validation_loss_siamese : 0.1396\n",
      "validation_accuracy_siamese : 85.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2970\n",
      "training_loss_siamese : 0.0020\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0627\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 2970\n",
      "validation_loss_siamese : 0.0999\n",
      "validation_accuracy_siamese : 90.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2980\n",
      "training_loss_siamese : 0.0073\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.0630\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 2980\n",
      "validation_loss_siamese : 0.1283\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 2990\n",
      "training_loss_siamese : 0.0077\n",
      "training_accuracy_siamese : 99.00%\n",
      "training_loss_classifier : 0.0675\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 2990\n",
      "validation_loss_siamese : 0.1262\n",
      "validation_accuracy_siamese : 86.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3000\n",
      "training_loss_siamese : 0.0064\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.0657\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 3000\n",
      "validation_loss_siamese : 0.1186\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3010\n",
      "training_loss_siamese : 0.0099\n",
      "training_accuracy_siamese : 99.00%\n",
      "training_loss_classifier : 0.0637\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3010\n",
      "validation_loss_siamese : 0.1294\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3020\n",
      "training_loss_siamese : 0.0009\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0578\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3020\n",
      "validation_loss_siamese : 0.1256\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3030\n",
      "training_loss_siamese : 0.0058\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.0659\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 3030\n",
      "validation_loss_siamese : 0.1202\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3040\n",
      "training_loss_siamese : 0.0042\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0604\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3040\n",
      "validation_loss_siamese : 0.1440\n",
      "validation_accuracy_siamese : 84.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3050\n",
      "training_loss_siamese : 0.0053\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0609\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3050\n",
      "validation_loss_siamese : 0.1453\n",
      "validation_accuracy_siamese : 84.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3060\n",
      "training_loss_siamese : 0.0054\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.0599\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3060\n",
      "validation_loss_siamese : 0.1341\n",
      "validation_accuracy_siamese : 86.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3070\n",
      "training_loss_siamese : 0.0050\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0683\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 3070\n",
      "validation_loss_siamese : 0.1229\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3080\n",
      "training_loss_siamese : 0.0022\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0601\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3080\n",
      "validation_loss_siamese : 0.1115\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3090\n",
      "training_loss_siamese : 0.0000\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0551\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3090\n",
      "validation_loss_siamese : 0.1481\n",
      "validation_accuracy_siamese : 84.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3100\n",
      "training_loss_siamese : 0.0014\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0563\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3100\n",
      "validation_loss_siamese : 0.1271\n",
      "validation_accuracy_siamese : 86.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3110\n",
      "training_loss_siamese : 0.0040\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0600\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3110\n",
      "validation_loss_siamese : 0.1316\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3120\n",
      "training_loss_siamese : 0.0027\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0600\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3120\n",
      "validation_loss_siamese : 0.1285\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3130\n",
      "training_loss_siamese : 0.0040\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0527\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3130\n",
      "validation_loss_siamese : 0.1469\n",
      "validation_accuracy_siamese : 84.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3140\n",
      "training_loss_siamese : 0.0085\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.0641\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 3140\n",
      "validation_loss_siamese : 0.1397\n",
      "validation_accuracy_siamese : 85.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3150\n",
      "training_loss_siamese : 0.0020\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0580\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3150\n",
      "validation_loss_siamese : 0.0931\n",
      "validation_accuracy_siamese : 89.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3160\n",
      "training_loss_siamese : 0.0000\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0520\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3160\n",
      "validation_loss_siamese : 0.1402\n",
      "validation_accuracy_siamese : 85.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3170\n",
      "training_loss_siamese : 0.0024\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0578\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3170\n",
      "validation_loss_siamese : 0.1481\n",
      "validation_accuracy_siamese : 85.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3180\n",
      "training_loss_siamese : 0.0020\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0508\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3180\n",
      "validation_loss_siamese : 0.1162\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3190\n",
      "training_loss_siamese : 0.0051\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0570\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3190\n",
      "validation_loss_siamese : 0.1412\n",
      "validation_accuracy_siamese : 85.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3200\n",
      "training_loss_siamese : 0.0060\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0545\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3200\n",
      "validation_loss_siamese : 0.1421\n",
      "validation_accuracy_siamese : 85.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3210\n",
      "training_loss_siamese : 0.0046\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0595\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 3210\n",
      "validation_loss_siamese : 0.1144\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3220\n",
      "training_loss_siamese : 0.0020\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0510\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3220\n",
      "validation_loss_siamese : 0.1275\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3230\n",
      "training_loss_siamese : 0.0030\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0512\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3230\n",
      "validation_loss_siamese : 0.1080\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3240\n",
      "training_loss_siamese : 0.0003\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0510\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3240\n",
      "validation_loss_siamese : 0.1204\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3250\n",
      "training_loss_siamese : 0.0010\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0502\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3250\n",
      "validation_loss_siamese : 0.1048\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3260\n",
      "training_loss_siamese : 0.0058\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0504\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3260\n",
      "validation_loss_siamese : 0.1000\n",
      "validation_accuracy_siamese : 89.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3270\n",
      "training_loss_siamese : 0.0072\n",
      "training_accuracy_siamese : 99.00%\n",
      "training_loss_classifier : 0.0642\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 3270\n",
      "validation_loss_siamese : 0.1319\n",
      "validation_accuracy_siamese : 85.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3280\n",
      "training_loss_siamese : 0.0056\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0500\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3280\n",
      "validation_loss_siamese : 0.1541\n",
      "validation_accuracy_siamese : 84.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3290\n",
      "training_loss_siamese : 0.0043\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0559\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 3290\n",
      "validation_loss_siamese : 0.1681\n",
      "validation_accuracy_siamese : 82.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3300\n",
      "training_loss_siamese : 0.0023\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0552\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3300\n",
      "validation_loss_siamese : 0.1085\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3310\n",
      "training_loss_siamese : 0.0041\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0537\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3310\n",
      "validation_loss_siamese : 0.1334\n",
      "validation_accuracy_siamese : 86.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3320\n",
      "training_loss_siamese : 0.0039\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0543\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3320\n",
      "validation_loss_siamese : 0.1302\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3330\n",
      "training_loss_siamese : 0.0085\n",
      "training_accuracy_siamese : 99.00%\n",
      "training_loss_classifier : 0.0631\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 3330\n",
      "validation_loss_siamese : 0.0756\n",
      "validation_accuracy_siamese : 92.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3340\n",
      "training_loss_siamese : 0.0012\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0498\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3340\n",
      "validation_loss_siamese : 0.1337\n",
      "validation_accuracy_siamese : 86.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3350\n",
      "training_loss_siamese : 0.0048\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0549\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3350\n",
      "validation_loss_siamese : 0.0956\n",
      "validation_accuracy_siamese : 90.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3360\n",
      "training_loss_siamese : 0.0021\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0476\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3360\n",
      "validation_loss_siamese : 0.1546\n",
      "validation_accuracy_siamese : 83.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3370\n",
      "training_loss_siamese : 0.0018\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0519\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3370\n",
      "validation_loss_siamese : 0.1546\n",
      "validation_accuracy_siamese : 84.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3380\n",
      "training_loss_siamese : 0.0022\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0471\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3380\n",
      "validation_loss_siamese : 0.1176\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3390\n",
      "training_loss_siamese : 0.0036\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0528\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3390\n",
      "validation_loss_siamese : 0.1495\n",
      "validation_accuracy_siamese : 84.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3400\n",
      "training_loss_siamese : 0.0031\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0528\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3400\n",
      "validation_loss_siamese : 0.1248\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3410\n",
      "training_loss_siamese : 0.0000\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0472\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3410\n",
      "validation_loss_siamese : 0.1236\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3420\n",
      "training_loss_siamese : 0.0022\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0497\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3420\n",
      "validation_loss_siamese : 0.1038\n",
      "validation_accuracy_siamese : 89.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3430\n",
      "training_loss_siamese : 0.0020\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0519\n",
      "training_accuracy_classifier : 99.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************\n",
      "batch_i : 3430\n",
      "validation_loss_siamese : 0.1338\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3440\n",
      "training_loss_siamese : 0.0026\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0520\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3440\n",
      "validation_loss_siamese : 0.1338\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3450\n",
      "training_loss_siamese : 0.0004\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0457\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3450\n",
      "validation_loss_siamese : 0.1243\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3460\n",
      "training_loss_siamese : 0.0016\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0506\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3460\n",
      "validation_loss_siamese : 0.1632\n",
      "validation_accuracy_siamese : 83.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3470\n",
      "training_loss_siamese : 0.0015\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0447\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3470\n",
      "validation_loss_siamese : 0.1094\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3480\n",
      "training_loss_siamese : 0.0020\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0451\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3480\n",
      "validation_loss_siamese : 0.2173\n",
      "validation_accuracy_siamese : 77.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3490\n",
      "training_loss_siamese : 0.0037\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0490\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3490\n",
      "validation_loss_siamese : 0.1303\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3500\n",
      "training_loss_siamese : 0.0038\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0487\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3500\n",
      "validation_loss_siamese : 0.1669\n",
      "validation_accuracy_siamese : 83.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3510\n",
      "training_loss_siamese : 0.0012\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0449\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3510\n",
      "validation_loss_siamese : 0.1339\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3520\n",
      "training_loss_siamese : 0.0005\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0444\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3520\n",
      "validation_loss_siamese : 0.1302\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3530\n",
      "training_loss_siamese : 0.0001\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0442\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3530\n",
      "validation_loss_siamese : 0.0880\n",
      "validation_accuracy_siamese : 91.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3540\n",
      "training_loss_siamese : 0.0062\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0446\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3540\n",
      "validation_loss_siamese : 0.1521\n",
      "validation_accuracy_siamese : 84.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3550\n",
      "training_loss_siamese : 0.0057\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0493\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3550\n",
      "validation_loss_siamese : 0.1254\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3560\n",
      "training_loss_siamese : 0.0004\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0437\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3560\n",
      "validation_loss_siamese : 0.1182\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3570\n",
      "training_loss_siamese : 0.0001\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0436\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3570\n",
      "validation_loss_siamese : 0.1608\n",
      "validation_accuracy_siamese : 83.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3580\n",
      "training_loss_siamese : 0.0021\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0481\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3580\n",
      "validation_loss_siamese : 0.1297\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3590\n",
      "training_loss_siamese : 0.0046\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0505\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 3590\n",
      "validation_loss_siamese : 0.1394\n",
      "validation_accuracy_siamese : 85.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3600\n",
      "training_loss_siamese : 0.0040\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0528\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 3600\n",
      "validation_loss_siamese : 0.1265\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3610\n",
      "training_loss_siamese : 0.0000\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0421\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3610\n",
      "validation_loss_siamese : 0.1229\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3620\n",
      "training_loss_siamese : 0.0051\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.0489\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 3620\n",
      "validation_loss_siamese : 0.1155\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3630\n",
      "training_loss_siamese : 0.0020\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0420\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3630\n",
      "validation_loss_siamese : 0.1046\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3640\n",
      "training_loss_siamese : 0.0020\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0419\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3640\n",
      "validation_loss_siamese : 0.0958\n",
      "validation_accuracy_siamese : 89.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3650\n",
      "training_loss_siamese : 0.0021\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0424\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3650\n",
      "validation_loss_siamese : 0.1232\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3660\n",
      "training_loss_siamese : 0.0085\n",
      "training_accuracy_siamese : 99.00%\n",
      "training_loss_classifier : 0.0540\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 3660\n",
      "validation_loss_siamese : 0.1420\n",
      "validation_accuracy_siamese : 85.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3670\n",
      "training_loss_siamese : 0.0004\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0413\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3670\n",
      "validation_loss_siamese : 0.1635\n",
      "validation_accuracy_siamese : 83.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3680\n",
      "training_loss_siamese : 0.0037\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0461\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3680\n",
      "validation_loss_siamese : 0.1098\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3690\n",
      "training_loss_siamese : 0.0024\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0458\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3690\n",
      "validation_loss_siamese : 0.1793\n",
      "validation_accuracy_siamese : 82.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3700\n",
      "training_loss_siamese : 0.0065\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.0539\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 3700\n",
      "validation_loss_siamese : 0.1393\n",
      "validation_accuracy_siamese : 85.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3710\n",
      "training_loss_siamese : 0.0053\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0518\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 3710\n",
      "validation_loss_siamese : 0.1096\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3720\n",
      "training_loss_siamese : 0.0010\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0403\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3720\n",
      "validation_loss_siamese : 0.1413\n",
      "validation_accuracy_siamese : 85.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3730\n",
      "training_loss_siamese : 0.0061\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0458\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3730\n",
      "validation_loss_siamese : 0.1383\n",
      "validation_accuracy_siamese : 86.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3740\n",
      "training_loss_siamese : 0.0023\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0457\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3740\n",
      "validation_loss_siamese : 0.1323\n",
      "validation_accuracy_siamese : 86.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3750\n",
      "training_loss_siamese : 0.0020\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0453\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3750\n",
      "validation_loss_siamese : 0.1566\n",
      "validation_accuracy_siamese : 84.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3760\n",
      "training_loss_siamese : 0.0055\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0441\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3760\n",
      "validation_loss_siamese : 0.1462\n",
      "validation_accuracy_siamese : 85.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3770\n",
      "training_loss_siamese : 0.0040\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0515\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 3770\n",
      "validation_loss_siamese : 0.1496\n",
      "validation_accuracy_siamese : 84.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3780\n",
      "training_loss_siamese : 0.0020\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0458\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3780\n",
      "validation_loss_siamese : 0.1283\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3790\n",
      "training_loss_siamese : 0.0044\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0476\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 3790\n",
      "validation_loss_siamese : 0.1675\n",
      "validation_accuracy_siamese : 83.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3800\n",
      "training_loss_siamese : 0.0021\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0391\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3800\n",
      "validation_loss_siamese : 0.1509\n",
      "validation_accuracy_siamese : 84.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3810\n",
      "training_loss_siamese : 0.0011\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0413\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3810\n",
      "validation_loss_siamese : 0.1549\n",
      "validation_accuracy_siamese : 84.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3820\n",
      "training_loss_siamese : 0.0058\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0435\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3820\n",
      "validation_loss_siamese : 0.1530\n",
      "validation_accuracy_siamese : 84.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3830\n",
      "training_loss_siamese : 0.0028\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0443\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3830\n",
      "validation_loss_siamese : 0.1232\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3840\n",
      "training_loss_siamese : 0.0055\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0434\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3840\n",
      "validation_loss_siamese : 0.1251\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3850\n",
      "training_loss_siamese : 0.0025\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0437\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3850\n",
      "validation_loss_siamese : 0.0917\n",
      "validation_accuracy_siamese : 91.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3860\n",
      "training_loss_siamese : 0.0001\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0364\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3860\n",
      "validation_loss_siamese : 0.1596\n",
      "validation_accuracy_siamese : 84.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3870\n",
      "training_loss_siamese : 0.0001\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0369\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3870\n",
      "validation_loss_siamese : 0.1268\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3880\n",
      "training_loss_siamese : 0.0022\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0419\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3880\n",
      "validation_loss_siamese : 0.1259\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3890\n",
      "training_loss_siamese : 0.0011\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0365\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3890\n",
      "validation_loss_siamese : 0.1562\n",
      "validation_accuracy_siamese : 84.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3900\n",
      "training_loss_siamese : 0.0041\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0373\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3900\n",
      "validation_loss_siamese : 0.1273\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3910\n",
      "training_loss_siamese : 0.0015\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0372\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3910\n",
      "validation_loss_siamese : 0.1578\n",
      "validation_accuracy_siamese : 84.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3920\n",
      "training_loss_siamese : 0.0029\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0428\n",
      "training_accuracy_classifier : 99.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************\n",
      "batch_i : 3920\n",
      "validation_loss_siamese : 0.1770\n",
      "validation_accuracy_siamese : 82.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3930\n",
      "training_loss_siamese : 0.0000\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0363\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3930\n",
      "validation_loss_siamese : 0.1655\n",
      "validation_accuracy_siamese : 83.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3940\n",
      "training_loss_siamese : 0.0000\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0361\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3940\n",
      "validation_loss_siamese : 0.1375\n",
      "validation_accuracy_siamese : 86.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3950\n",
      "training_loss_siamese : 0.0001\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0369\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3950\n",
      "validation_loss_siamese : 0.1427\n",
      "validation_accuracy_siamese : 85.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3960\n",
      "training_loss_siamese : 0.0020\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0358\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 3960\n",
      "validation_loss_siamese : 0.1550\n",
      "validation_accuracy_siamese : 84.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3970\n",
      "training_loss_siamese : 0.0073\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.0460\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 3970\n",
      "validation_loss_siamese : 0.1754\n",
      "validation_accuracy_siamese : 82.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3980\n",
      "training_loss_siamese : 0.0031\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0394\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3980\n",
      "validation_loss_siamese : 0.1730\n",
      "validation_accuracy_siamese : 82.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 3990\n",
      "training_loss_siamese : 0.0020\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0415\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 3990\n",
      "validation_loss_siamese : 0.1199\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4000\n",
      "training_loss_siamese : 0.0043\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0416\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4000\n",
      "validation_loss_siamese : 0.1426\n",
      "validation_accuracy_siamese : 85.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4010\n",
      "training_loss_siamese : 0.0009\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0343\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4010\n",
      "validation_loss_siamese : 0.1057\n",
      "validation_accuracy_siamese : 89.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4020\n",
      "training_loss_siamese : 0.0007\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0364\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4020\n",
      "validation_loss_siamese : 0.1492\n",
      "validation_accuracy_siamese : 85.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4030\n",
      "training_loss_siamese : 0.0020\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0408\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4030\n",
      "validation_loss_siamese : 0.1068\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4040\n",
      "training_loss_siamese : 0.0042\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0414\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 4040\n",
      "validation_loss_siamese : 0.1590\n",
      "validation_accuracy_siamese : 84.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4050\n",
      "training_loss_siamese : 0.0000\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0345\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4050\n",
      "validation_loss_siamese : 0.1491\n",
      "validation_accuracy_siamese : 85.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4060\n",
      "training_loss_siamese : 0.0056\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0335\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4060\n",
      "validation_loss_siamese : 0.1414\n",
      "validation_accuracy_siamese : 85.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4070\n",
      "training_loss_siamese : 0.0025\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0408\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4070\n",
      "validation_loss_siamese : 0.1379\n",
      "validation_accuracy_siamese : 85.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4080\n",
      "training_loss_siamese : 0.0022\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0348\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4080\n",
      "validation_loss_siamese : 0.1709\n",
      "validation_accuracy_siamese : 82.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4090\n",
      "training_loss_siamese : 0.0042\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0405\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4090\n",
      "validation_loss_siamese : 0.1430\n",
      "validation_accuracy_siamese : 85.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4100\n",
      "training_loss_siamese : 0.0000\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0336\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4100\n",
      "validation_loss_siamese : 0.1598\n",
      "validation_accuracy_siamese : 84.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4110\n",
      "training_loss_siamese : 0.0012\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0342\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4110\n",
      "validation_loss_siamese : 0.1542\n",
      "validation_accuracy_siamese : 84.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4120\n",
      "training_loss_siamese : 0.0018\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0330\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4120\n",
      "validation_loss_siamese : 0.1182\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4130\n",
      "training_loss_siamese : 0.0034\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0370\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4130\n",
      "validation_loss_siamese : 0.1285\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4140\n",
      "training_loss_siamese : 0.0040\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0391\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4140\n",
      "validation_loss_siamese : 0.1592\n",
      "validation_accuracy_siamese : 84.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4150\n",
      "training_loss_siamese : 0.0035\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0323\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4150\n",
      "validation_loss_siamese : 0.1531\n",
      "validation_accuracy_siamese : 84.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4160\n",
      "training_loss_siamese : 0.0022\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0388\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4160\n",
      "validation_loss_siamese : 0.1697\n",
      "validation_accuracy_siamese : 83.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4170\n",
      "training_loss_siamese : 0.0002\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0334\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4170\n",
      "validation_loss_siamese : 0.1387\n",
      "validation_accuracy_siamese : 86.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4180\n",
      "training_loss_siamese : 0.0034\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0427\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 4180\n",
      "validation_loss_siamese : 0.1350\n",
      "validation_accuracy_siamese : 86.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4190\n",
      "training_loss_siamese : 0.0035\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0323\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4190\n",
      "validation_loss_siamese : 0.1649\n",
      "validation_accuracy_siamese : 82.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4200\n",
      "training_loss_siamese : 0.0020\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0313\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4200\n",
      "validation_loss_siamese : 0.1368\n",
      "validation_accuracy_siamese : 86.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4210\n",
      "training_loss_siamese : 0.0000\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0316\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4210\n",
      "validation_loss_siamese : 0.1546\n",
      "validation_accuracy_siamese : 84.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4220\n",
      "training_loss_siamese : 0.0058\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0366\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4220\n",
      "validation_loss_siamese : 0.1391\n",
      "validation_accuracy_siamese : 86.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4230\n",
      "training_loss_siamese : 0.0010\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0316\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4230\n",
      "validation_loss_siamese : 0.1348\n",
      "validation_accuracy_siamese : 86.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4240\n",
      "training_loss_siamese : 0.0000\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0318\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4240\n",
      "validation_loss_siamese : 0.1579\n",
      "validation_accuracy_siamese : 84.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4250\n",
      "training_loss_siamese : 0.0041\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0442\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 4250\n",
      "validation_loss_siamese : 0.1229\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4260\n",
      "training_loss_siamese : 0.0018\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0354\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4260\n",
      "validation_loss_siamese : 0.1746\n",
      "validation_accuracy_siamese : 82.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4270\n",
      "training_loss_siamese : 0.0025\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0310\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4270\n",
      "validation_loss_siamese : 0.1138\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4280\n",
      "training_loss_siamese : 0.0000\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0302\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4280\n",
      "validation_loss_siamese : 0.1344\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4290\n",
      "training_loss_siamese : 0.0052\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0392\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 4290\n",
      "validation_loss_siamese : 0.1060\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4300\n",
      "training_loss_siamese : 0.0042\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0433\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 4300\n",
      "validation_loss_siamese : 0.1559\n",
      "validation_accuracy_siamese : 84.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4310\n",
      "training_loss_siamese : 0.0003\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0306\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4310\n",
      "validation_loss_siamese : 0.1216\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4320\n",
      "training_loss_siamese : 0.0056\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0362\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4320\n",
      "validation_loss_siamese : 0.1043\n",
      "validation_accuracy_siamese : 89.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4330\n",
      "training_loss_siamese : 0.0024\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0366\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4330\n",
      "validation_loss_siamese : 0.1079\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4340\n",
      "training_loss_siamese : 0.0017\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0299\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4340\n",
      "validation_loss_siamese : 0.1445\n",
      "validation_accuracy_siamese : 85.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4350\n",
      "training_loss_siamese : 0.0022\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0364\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4350\n",
      "validation_loss_siamese : 0.1449\n",
      "validation_accuracy_siamese : 85.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4360\n",
      "training_loss_siamese : 0.0000\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0293\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4360\n",
      "validation_loss_siamese : 0.1461\n",
      "validation_accuracy_siamese : 85.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4370\n",
      "training_loss_siamese : 0.0037\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0306\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4370\n",
      "validation_loss_siamese : 0.1203\n",
      "validation_accuracy_siamese : 88.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4380\n",
      "training_loss_siamese : 0.0022\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0355\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4380\n",
      "validation_loss_siamese : 0.0871\n",
      "validation_accuracy_siamese : 91.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4390\n",
      "training_loss_siamese : 0.0020\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0354\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4390\n",
      "validation_loss_siamese : 0.1479\n",
      "validation_accuracy_siamese : 85.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4400\n",
      "training_loss_siamese : 0.0021\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0299\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4400\n",
      "validation_loss_siamese : 0.1722\n",
      "validation_accuracy_siamese : 82.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4410\n",
      "training_loss_siamese : 0.0074\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.0284\n",
      "training_accuracy_classifier : 100.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************\n",
      "batch_i : 4410\n",
      "validation_loss_siamese : 0.0936\n",
      "validation_accuracy_siamese : 90.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4420\n",
      "training_loss_siamese : 0.0048\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0291\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4420\n",
      "validation_loss_siamese : 0.1565\n",
      "validation_accuracy_siamese : 84.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4430\n",
      "training_loss_siamese : 0.0084\n",
      "training_accuracy_siamese : 99.00%\n",
      "training_loss_classifier : 0.0414\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 4430\n",
      "validation_loss_siamese : 0.1135\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4440\n",
      "training_loss_siamese : 0.0020\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0355\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4440\n",
      "validation_loss_siamese : 0.1656\n",
      "validation_accuracy_siamese : 83.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4450\n",
      "training_loss_siamese : 0.0055\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0404\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 4450\n",
      "validation_loss_siamese : 0.1502\n",
      "validation_accuracy_siamese : 85.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4460\n",
      "training_loss_siamese : 0.0013\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0318\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4460\n",
      "validation_loss_siamese : 0.1216\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4470\n",
      "training_loss_siamese : 0.0035\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0368\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 4470\n",
      "validation_loss_siamese : 0.1397\n",
      "validation_accuracy_siamese : 86.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4480\n",
      "training_loss_siamese : 0.0011\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0319\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4480\n",
      "validation_loss_siamese : 0.1721\n",
      "validation_accuracy_siamese : 82.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4490\n",
      "training_loss_siamese : 0.0062\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0342\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4490\n",
      "validation_loss_siamese : 0.1649\n",
      "validation_accuracy_siamese : 83.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4500\n",
      "training_loss_siamese : 0.0020\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0344\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4500\n",
      "validation_loss_siamese : 0.0952\n",
      "validation_accuracy_siamese : 90.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4510\n",
      "training_loss_siamese : 0.0023\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0276\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4510\n",
      "validation_loss_siamese : 0.1157\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4520\n",
      "training_loss_siamese : 0.0056\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0464\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 4520\n",
      "validation_loss_siamese : 0.1508\n",
      "validation_accuracy_siamese : 84.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4530\n",
      "training_loss_siamese : 0.0001\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0273\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4530\n",
      "validation_loss_siamese : 0.1687\n",
      "validation_accuracy_siamese : 82.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4540\n",
      "training_loss_siamese : 0.0020\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0337\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4540\n",
      "validation_loss_siamese : 0.1325\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4550\n",
      "training_loss_siamese : 0.0019\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0329\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4550\n",
      "validation_loss_siamese : 0.1040\n",
      "validation_accuracy_siamese : 89.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4560\n",
      "training_loss_siamese : 0.0029\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0314\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4560\n",
      "validation_loss_siamese : 0.1531\n",
      "validation_accuracy_siamese : 84.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4570\n",
      "training_loss_siamese : 0.0035\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0268\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4570\n",
      "validation_loss_siamese : 0.1248\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4580\n",
      "training_loss_siamese : 0.0007\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0270\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4580\n",
      "validation_loss_siamese : 0.1347\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4590\n",
      "training_loss_siamese : 0.0020\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0334\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4590\n",
      "validation_loss_siamese : 0.1319\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4600\n",
      "training_loss_siamese : 0.0029\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0295\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4600\n",
      "validation_loss_siamese : 0.1497\n",
      "validation_accuracy_siamese : 85.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4610\n",
      "training_loss_siamese : 0.0019\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0330\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4610\n",
      "validation_loss_siamese : 0.1547\n",
      "validation_accuracy_siamese : 84.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4620\n",
      "training_loss_siamese : 0.0021\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0326\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4620\n",
      "validation_loss_siamese : 0.1145\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4630\n",
      "training_loss_siamese : 0.0041\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0390\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 4630\n",
      "validation_loss_siamese : 0.1448\n",
      "validation_accuracy_siamese : 85.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4640\n",
      "training_loss_siamese : 0.0000\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0256\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4640\n",
      "validation_loss_siamese : 0.0949\n",
      "validation_accuracy_siamese : 90.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4650\n",
      "training_loss_siamese : 0.0040\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0328\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4650\n",
      "validation_loss_siamese : 0.1604\n",
      "validation_accuracy_siamese : 84.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4660\n",
      "training_loss_siamese : 0.0024\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0326\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4660\n",
      "validation_loss_siamese : 0.0843\n",
      "validation_accuracy_siamese : 91.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4670\n",
      "training_loss_siamese : 0.0046\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0412\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 4670\n",
      "validation_loss_siamese : 0.1395\n",
      "validation_accuracy_siamese : 86.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4680\n",
      "training_loss_siamese : 0.0040\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0253\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4680\n",
      "validation_loss_siamese : 0.1398\n",
      "validation_accuracy_siamese : 86.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4690\n",
      "training_loss_siamese : 0.0069\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.0331\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4690\n",
      "validation_loss_siamese : 0.1298\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4700\n",
      "training_loss_siamese : 0.0000\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0253\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4700\n",
      "validation_loss_siamese : 0.1451\n",
      "validation_accuracy_siamese : 85.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4710\n",
      "training_loss_siamese : 0.0021\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0331\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4710\n",
      "validation_loss_siamese : 0.1290\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4720\n",
      "training_loss_siamese : 0.0020\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0252\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4720\n",
      "validation_loss_siamese : 0.1098\n",
      "validation_accuracy_siamese : 89.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4730\n",
      "training_loss_siamese : 0.0039\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0313\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4730\n",
      "validation_loss_siamese : 0.1652\n",
      "validation_accuracy_siamese : 83.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4740\n",
      "training_loss_siamese : 0.0048\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0408\n",
      "training_accuracy_classifier : 99.40%\n",
      "\n",
      "******************************\n",
      "batch_i : 4740\n",
      "validation_loss_siamese : 0.1645\n",
      "validation_accuracy_siamese : 83.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4750\n",
      "training_loss_siamese : 0.0051\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0268\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4750\n",
      "validation_loss_siamese : 0.1343\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4760\n",
      "training_loss_siamese : 0.0037\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0306\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4760\n",
      "validation_loss_siamese : 0.1046\n",
      "validation_accuracy_siamese : 89.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4770\n",
      "training_loss_siamese : 0.0027\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0264\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4770\n",
      "validation_loss_siamese : 0.1307\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4780\n",
      "training_loss_siamese : 0.0000\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0243\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4780\n",
      "validation_loss_siamese : 0.1731\n",
      "validation_accuracy_siamese : 82.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4790\n",
      "training_loss_siamese : 0.0030\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0295\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4790\n",
      "validation_loss_siamese : 0.1551\n",
      "validation_accuracy_siamese : 84.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4800\n",
      "training_loss_siamese : 0.0022\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0242\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4800\n",
      "validation_loss_siamese : 0.1507\n",
      "validation_accuracy_siamese : 85.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4810\n",
      "training_loss_siamese : 0.0022\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0248\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4810\n",
      "validation_loss_siamese : 0.1803\n",
      "validation_accuracy_siamese : 82.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4820\n",
      "training_loss_siamese : 0.0000\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0239\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4820\n",
      "validation_loss_siamese : 0.1027\n",
      "validation_accuracy_siamese : 89.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4830\n",
      "training_loss_siamese : 0.0040\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0243\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4830\n",
      "validation_loss_siamese : 0.1501\n",
      "validation_accuracy_siamese : 85.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4840\n",
      "training_loss_siamese : 0.0041\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0376\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 4840\n",
      "validation_loss_siamese : 0.1727\n",
      "validation_accuracy_siamese : 83.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4850\n",
      "training_loss_siamese : 0.0003\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0241\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4850\n",
      "validation_loss_siamese : 0.1150\n",
      "validation_accuracy_siamese : 88.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4860\n",
      "training_loss_siamese : 0.0000\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0239\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4860\n",
      "validation_loss_siamese : 0.1313\n",
      "validation_accuracy_siamese : 87.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4870\n",
      "training_loss_siamese : 0.0000\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0235\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4870\n",
      "validation_loss_siamese : 0.1534\n",
      "validation_accuracy_siamese : 84.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4880\n",
      "training_loss_siamese : 0.0002\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0233\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4880\n",
      "validation_loss_siamese : 0.0894\n",
      "validation_accuracy_siamese : 91.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4890\n",
      "training_loss_siamese : 0.0020\n",
      "training_accuracy_siamese : 99.80%\n",
      "training_loss_classifier : 0.0300\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4890\n",
      "validation_loss_siamese : 0.1328\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4900\n",
      "training_loss_siamese : 0.0028\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0261\n",
      "training_accuracy_classifier : 99.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************\n",
      "batch_i : 4900\n",
      "validation_loss_siamese : 0.1713\n",
      "validation_accuracy_siamese : 82.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4910\n",
      "training_loss_siamese : 0.0000\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0230\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4910\n",
      "validation_loss_siamese : 0.1375\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4920\n",
      "training_loss_siamese : 0.0063\n",
      "training_accuracy_siamese : 99.20%\n",
      "training_loss_classifier : 0.0347\n",
      "training_accuracy_classifier : 99.60%\n",
      "\n",
      "******************************\n",
      "batch_i : 4920\n",
      "validation_loss_siamese : 0.1256\n",
      "validation_accuracy_siamese : 87.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4930\n",
      "training_loss_siamese : 0.0003\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0239\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4930\n",
      "validation_loss_siamese : 0.1649\n",
      "validation_accuracy_siamese : 83.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4940\n",
      "training_loss_siamese : 0.0025\n",
      "training_accuracy_siamese : 99.60%\n",
      "training_loss_classifier : 0.0230\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4940\n",
      "validation_loss_siamese : 0.1687\n",
      "validation_accuracy_siamese : 83.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4950\n",
      "training_loss_siamese : 0.0003\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0229\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4950\n",
      "validation_loss_siamese : 0.1352\n",
      "validation_accuracy_siamese : 86.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4960\n",
      "training_loss_siamese : 0.0000\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0227\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4960\n",
      "validation_loss_siamese : 0.1401\n",
      "validation_accuracy_siamese : 86.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4970\n",
      "training_loss_siamese : 0.0058\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0288\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4970\n",
      "validation_loss_siamese : 0.0945\n",
      "validation_accuracy_siamese : 90.50%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4980\n",
      "training_loss_siamese : 0.0047\n",
      "training_accuracy_siamese : 99.40%\n",
      "training_loss_classifier : 0.0244\n",
      "training_accuracy_classifier : 99.80%\n",
      "\n",
      "******************************\n",
      "batch_i : 4980\n",
      "validation_loss_siamese : 0.1385\n",
      "validation_accuracy_siamese : 86.00%\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "batch_i : 4990\n",
      "training_loss_siamese : 0.0000\n",
      "training_accuracy_siamese : 100.00%\n",
      "training_loss_classifier : 0.0226\n",
      "training_accuracy_classifier : 100.00%\n",
      "\n",
      "******************************\n",
      "batch_i : 4990\n",
      "validation_loss_siamese : 0.1805\n",
      "validation_accuracy_siamese : 81.00%\n",
      "****************************** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "val_loss_siamese_record = []\n",
    "for batch_i in range(0 , 5000):\n",
    "    # 每經過5個batch，就會利用oversampler合成不同的\"標籤為0\"的data(較少數的data)\n",
    "    # 以防止network看過太多同樣的data，進而產生overfitting的現象\n",
    "    if batch_i % 5 == 0:\n",
    "        decision_oversampler = np.random.randint(0 , 4)\n",
    "        if decision_oversampler == 0:\n",
    "            oversampler = SMOTE(n_jobs = -1)\n",
    "        elif decision_oversampler == 1:\n",
    "            oversampler = BorderlineSMOTE(kind = 'borderline-1' , n_jobs = -1)\n",
    "        elif decision_oversampler == 2:\n",
    "            oversampler = BorderlineSMOTE(kind = 'borderline-2' , n_jobs = -1)\n",
    "        elif decision_oversampler == 3:\n",
    "            oversampler = ADASYN(n_jobs = -1)\n",
    "        x_train_oversample , y_train_oversample = oversampler.fit_sample(x_train , y_train)\n",
    "\n",
    "    x_batch , y_batch = get_batch(x_train_oversample , y_train_oversample)\n",
    "\n",
    "    sess.run([train_siamese , train_classifier] , feed_dict = {input_tensor : x_batch  ,\n",
    "                                                               y_true : y_batch ,\n",
    "                                                               keep_prob : 0.8})\n",
    "\n",
    "    if batch_i % 10 == 0:\n",
    "        train_loss_siamese , train_accuracy_siamese , train_loss_classifier , train_accuracy_classifier =\\\n",
    "        sess.run([contrastive_loss , accuracy_siamese , cross_entropy , accuracy_classifier] , feed_dict = {input_tensor : x_batch ,\n",
    "                                                                                                            y_true : y_batch ,\n",
    "                                                                                                            keep_prob : 1})\n",
    "\n",
    "        print('=' * 30)\n",
    "        print('batch_i : {}'.format(batch_i))\n",
    "        print('training_loss_siamese : {:.4f}'.format(train_loss_siamese))\n",
    "        print('training_accuracy_siamese : {:.2%}'.format(train_accuracy_siamese))\n",
    "        print('training_loss_classifier : {:.4f}'.format(train_loss_classifier))\n",
    "        print('training_accuracy_classifier : {:.2%}\\n'.format(train_accuracy_classifier))\n",
    "\n",
    "        x_val , y_val  = get_batch(x_test , y_test , batch_size = 200)\n",
    "\n",
    "        val_loss_siamese , val_accuracy_siamese = sess.run([contrastive_loss , accuracy_siamese] , feed_dict = {input_tensor : x_val ,\n",
    "                                                                                                                y_true : y_val ,\n",
    "                                                                                                                keep_prob : 1})\n",
    "    \n",
    "        print('*' * 30)\n",
    "        print('batch_i : {}'.format(batch_i))\n",
    "        print('validation_loss_siamese : {:.4f}'.format(val_loss_siamese))\n",
    "        print('validation_accuracy_siamese : {:.2%}'.format(val_accuracy_siamese))\n",
    "        print('*' * 30 , '\\n')\n",
    "\n",
    "        val_loss_siamese_record.append(val_loss_siamese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm , classes ,\n",
    "                          normalize = False,\n",
    "                          title = 'Confusion matrix',\n",
    "                          cmap = plt.cm.winter):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, fontsize=20)\n",
    "    plt.yticks(tick_marks, classes, fontsize=20)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", \n",
    "                  color=\"white\" if cm[i, j] < thresh else \"black\", fontsize=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', fontsize=20)\n",
    "    plt.xlabel('Predicted label', fontsize=20)\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall : 0.844\n",
      "Precision : 0.420\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# inference_方法1\n",
    "y_pred_1 = sess.run(tf.argmax(prediction_a_ , axis = 1) ,\n",
    "                    feed_dict = {x_a : x_test , keep_prob : 1})\n",
    "\n",
    "cm = confusion_matrix(y_test , y_pred_1)\n",
    "plot_confusion_matrix(cm , classes = [0 , 1] , normalize = False , title = 'Confusion matrix')\n",
    "recall = cm[1 , 1] / (cm[1 , 0] + cm[1 , 1])\n",
    "precision = cm[1 , 1] / (cm[0 , 1] + cm[1 , 1])\n",
    "print('Recall : {:.3f}'.format(recall))\n",
    "print('Precision : {:.3f}'.format(precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相對於 \"11_信用卡詐欺檢測_不均衡數據_undersample_oversample(SMOTE)\"<br>\n",
    "可以發現雖然犧牲了一點recall，但卻大幅度減少原本label為0，但被預測為1的情況<br>\n",
    "也就是大幅度提升模型預測data在\"label為0\"的能力，也可以說是大幅提升precision，但神奇的是卻只有稍微削減模型預測data在\"label為1\"的能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 85443/85443 [27:45<00:00, 51.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall : 0.857\n",
      "Precision : 0.339\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# inference_方法2(比較費時)\n",
    "# 隨機從label為0的x_train中抽出100筆data，再計算每筆x_test與抽出100筆data的距離\n",
    "# 若距離小於threshold，count_normal就加1\n",
    "# 若距離大於threshold，count_anomaly就加1\n",
    "# 如果count_normal大於count_anomaly，就將該筆x_test判定為0\n",
    "# 如果count_anomaly大於count_normal，就將該筆x_test判定為1\n",
    "threshold = 0.1\n",
    "x_train_normal = x_train[y_train == 0]\n",
    "y_pred_2 = np.zeros([85443 , ])\n",
    "for i in trange(0 , 85443):\n",
    "    count_normal = 0\n",
    "    count_anomaly = 0\n",
    "    normal_index = np.random.choice(len(x_train_normal) ,\n",
    "                                    size = 1000 ,\n",
    "                                    replace = False)\n",
    "    \n",
    "    x_normal_sample = x_train_normal[normal_index , :]\n",
    "    x_test_copy = [x_test[i , :] for _ in range(0 , 1000)]    \n",
    "    x_test_copy = np.array(x_test_copy)\n",
    "    \n",
    "    distance_ = sess.run(distance  ,\n",
    "                         feed_dict = {x_a : x_normal_sample ,\n",
    "                                      x_b : x_test_copy ,\n",
    "                                      keep_prob : 1})\n",
    "    \n",
    "    count_normal = (distance_ < threshold).sum()\n",
    "    count_anomaly = (distance_ >= threshold).sum()\n",
    "    if count_normal > count_anomaly:\n",
    "        y_pred_2[i] = 0\n",
    "    elif count_normal < count_anomaly:\n",
    "        y_pred_2[i] = 1\n",
    "    \n",
    "cm = confusion_matrix(y_test , y_pred_2)\n",
    "plot_confusion_matrix(cm , classes = [0 , 1] , normalize = False , title = 'Confusion matrix')\n",
    "recall = cm[1 , 1] / (cm[1 , 0] + cm[1 , 1])\n",
    "precision = cm[1 , 1] / (cm[0 , 1] + cm[1 , 1])\n",
    "print('Recall : {:.3f}'.format(recall))\n",
    "print('Precision : {:.3f}'.format(precision))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
